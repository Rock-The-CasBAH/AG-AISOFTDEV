{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "Here's a reusable Architectural Decision Record (ADR) template in markdown format:\n",
      "\n",
      "```markdown\n",
      "# Title: [Decision Title]\n",
      "\n",
      "**Status:** [Proposed | Accepted | Deprecated]\n",
      "\n",
      "## Context\n",
      "[Describe the problem, constraints, and forces influencing the decision. Include any relevant background information or business requirements that are driving this decision.]\n",
      "\n",
      "## Decision\n",
      "[State the decision clearly and explain the rationale behind it. Describe the solution you have chosen and why it is preferred over other alternatives.]\n",
      "\n",
      "## Consequences\n",
      "[List the expected benefits and potential drawbacks of the decision. Discuss both the positive and negative impacts it may have on the system or organization.]\n",
      "\n",
      "- **Positive Outcomes:** \n",
      "  - [Benefit 1]\n",
      "  - [Benefit 2]\n",
      "  - [Additional benefits...]\n",
      "\n",
      "- **Negative Outcomes:**\n",
      "  - [Drawback 1]\n",
      "  - [Drawback 2]\n",
      "  - [Additional drawbacks...]\n",
      "\n",
      "## Notes\n",
      "[Include any additional context, references to related documents, or links to further readings. This section can also contain notes about the implementation plan, stakeholders involved, or any assumptions and dependencies related to the decision.]\n",
      "```\n",
      "\n",
      "### Usage Instructions:\n",
      "- Replace placeholders (e.g., `[Decision Title]`, `[Describe the problem, constraints, and forces influencing the decision.]`) with actual content.\n",
      "- Choose the appropriate status in the \"Status\" section.\n",
      "- Use bullet points where necessary for clarity and organization.\n",
      "- Ensure this document is kept up-to-date in a version-controlled repository to track the evolution of architectural decisions over time.\n",
      "✅ Successfully saved artifact to: templates/adr_template.md\n",
      "Here's a reusable Architectural Decision Record (ADR) template in markdown format:\n",
      "\n",
      "```markdown\n",
      "# Title: [Decision Title]\n",
      "\n",
      "**Status:** [Proposed | Accepted | Deprecated]\n",
      "\n",
      "## Context\n",
      "[Describe the problem, constraints, and forces influencing the decision. Include any relevant background information or business requirements that are driving this decision.]\n",
      "\n",
      "## Decision\n",
      "[State the decision clearly and explain the rationale behind it. Describe the solution you have chosen and why it is preferred over other alternatives.]\n",
      "\n",
      "## Consequences\n",
      "[List the expected benefits and potential drawbacks of the decision. Discuss both the positive and negative impacts it may have on the system or organization.]\n",
      "\n",
      "- **Positive Outcomes:** \n",
      "  - [Benefit 1]\n",
      "  - [Benefit 2]\n",
      "  - [Additional benefits...]\n",
      "\n",
      "- **Negative Outcomes:**\n",
      "  - [Drawback 1]\n",
      "  - [Drawback 2]\n",
      "  - [Additional drawbacks...]\n",
      "\n",
      "## Notes\n",
      "[Include any additional context, references to related documents, or links to further readings. This section can also contain notes about the implementation plan, stakeholders involved, or any assumptions and dependencies related to the decision.]\n",
      "```\n",
      "\n",
      "### Usage Instructions:\n",
      "- Replace placeholders (e.g., `[Decision Title]`, `[Describe the problem, constraints, and forces influencing the decision.]`) with actual content.\n",
      "- Choose the appropriate status in the \"Status\" section.\n",
      "- Use bullet points where necessary for clarity and organization.\n",
      "- Ensure this document is kept up-to-date in a version-controlled repository to track the evolution of architectural decisions over time.\n",
      "✅ Successfully saved artifact to: templates/adr_template.md\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate a markdown ADR template.\n",
    "adr_template_prompt = \"\"\"\n",
    "You are an experienced technical writer specializing in software architecture documentation. Your task is to create a reusable Architectural Decision Record (ADR) template in markdown format. The template should be clean, professional, and adhere to industry best practices.\n",
    "\n",
    "### Requirements:\n",
    "1. **Title Section:**\n",
    "   - Include a placeholder for the ADR title.\n",
    "   - Example: `# Title: [Decision Title]`\n",
    "\n",
    "2. **Status Section:**\n",
    "   - Provide placeholders for status options such as `Proposed`, `Accepted`, or `Deprecated`.\n",
    "   - Example: `Status: [Proposed | Accepted | Deprecated]`\n",
    "\n",
    "3. **Context Section:**\n",
    "   - Include a detailed description of the problem or forces at play.\n",
    "   - Example: `## Context: [Describe the problem, constraints, and forces influencing the decision.]`\n",
    "\n",
    "4. **Decision Section:**\n",
    "   - Provide a clear structure for documenting the chosen solution.\n",
    "   - Example: `## Decision: [State the decision and its rationale.]`\n",
    "\n",
    "5. **Consequences Section:**\n",
    "   - Include placeholders for both positive and negative outcomes of the decision.\n",
    "   - Example: `## Consequences: [List the expected benefits and potential drawbacks.]`\n",
    "\n",
    "6. **Additional Notes:**\n",
    "   - Add a section for any supplementary information or references.\n",
    "   - Example: `## Notes: [Include any additional context or references.]`\n",
    "\n",
    "### Output:\n",
    "- Ensure the template is formatted in valid markdown.\n",
    "- Use comments or placeholders to guide users on how to fill out each section.\n",
    "- The output should be clean and ready for immediate use in a version-controlled repository.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "### Architectural Decision Record (ADR) - Semantic Search Database Technology\n",
      "\n",
      "#### Context\n",
      "The development team is tasked with designing a new hire onboarding tool for a small-to-medium sized enterprise. The tool requires a semantic search feature. The database design must adhere to scalability, modularity, TOGAF principles, ACID compliance, and compatibility with UML/SysML for future diagramming. Two database approaches are under consideration: PostgreSQL with the `pgvector` extension and a specialized vector database.\n",
      "\n",
      "---\n",
      "\n",
      "### Approach 1: PostgreSQL with the `pgvector` Extension\n",
      "\n",
      "#### Suitability for Semantic Search\n",
      "- **Semantic Search Capability:** `pgvector` enables PostgreSQL to handle vector data, allowing it to perform semantic searches by comparing vector similarities.\n",
      "- **Integration:** Seamlessly integrates with existing PostgreSQL deployments, making it suitable for teams already using PostgreSQL.\n",
      "\n",
      "#### Operational Complexity\n",
      "- **Complexity:** Moderate complexity as teams may need to understand both relational and vector data handling within the same system.\n",
      "- **Maintenance:** Familiar PostgreSQL ecosystem reduces the learning curve and operational overhead.\n",
      "\n",
      "#### Cost\n",
      "- **Cost-Effective:** Utilizes existing PostgreSQL infrastructure, minimizing additional hardware or software investments.\n",
      "- **Open Source:** PostgreSQL and `pgvector` are open-source, reducing software licensing costs.\n",
      "\n",
      "#### Query Flexibility\n",
      "- **Flexibility:** Supports both traditional SQL queries and vector-based semantic queries, offering a versatile querying environment.\n",
      "- **Limitations:** Performance may degrade with complex semantic queries compared to dedicated vector databases.\n",
      "\n",
      "#### Scalability\n",
      "- **Scalability:** PostgreSQL is well-suited for moderate scalability, but handling large-scale vector data could require additional resources and optimizations.\n",
      "- **Modularity:** Supports modular enhancements through extensions and plugins, aligning with TOGAF principles.\n",
      "\n",
      "#### Strengths\n",
      "- **ACID Compliance:** Inherently supports ACID transactions, ensuring data integrity and consistency.\n",
      "- **UML/SysML Compatibility:** Well-documented schema design practices in PostgreSQL facilitate diagramming.\n",
      "\n",
      "#### Limitations\n",
      "- **Performance:** May not match the high performance of specialized vector databases for large-scale semantic search tasks.\n",
      "- **Resource Intensive:** Increased resource consumption when handling large vector datasets.\n",
      "\n",
      "---\n",
      "\n",
      "### Approach 2: Specialized Vector Database (e.g., ChromaDB, FAISS, Weaviate)\n",
      "\n",
      "#### Performance for Semantic Search\n",
      "- **High Performance:** Designed specifically for vector operations, providing superior performance in semantic search tasks.\n",
      "- **Optimization:** Tailored optimizations for vector similarity searches lead to faster query responses.\n",
      "\n",
      "#### Operational Complexity\n",
      "- **Complexity:** Higher complexity due to specialized nature; requires learning new technologies and operational paradigms.\n",
      "- **Maintenance:** Potentially higher maintenance as teams must manage an additional database system.\n",
      "\n",
      "#### Cost\n",
      "- **Variable Costs:** May involve additional costs for specialized infrastructure or commercial solutions.\n",
      "- **Open Source Options:** Some databases offer open-source versions, but enterprise features might be behind paywalls.\n",
      "\n",
      "#### Query Flexibility\n",
      "- **Specialized Queries:** Optimized for vector queries, but may lack the flexibility of traditional SQL queries.\n",
      "- **Integration:** Additional effort required to integrate with existing relational databases for comprehensive querying capabilities.\n",
      "\n",
      "#### Scalability\n",
      "- **Scalability:** Highly scalable for vector data, designed to efficiently handle large volumes of high-dimensional data.\n",
      "- **Modularity:** Supports modular integration with other systems via APIs, aligning with TOGAF principles.\n",
      "\n",
      "#### Advantages\n",
      "- **Performance:** Superior performance for large-scale vector search tasks.\n",
      "- **Specialization:** Purpose-built for semantic search, offering advanced features and optimizations.\n",
      "\n",
      "#### Drawbacks\n",
      "- **ACID Compliance:** Not all vector databases provide ACID compliance, posing challenges for data integrity.\n",
      "- **UML/SysML Compatibility:** May require additional effort to represent vector database architectures in UML/SysML.\n",
      "\n",
      "---\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Both approaches offer unique benefits and challenges. PostgreSQL with `pgvector` provides a cost-effective, integrated solution with strong ACID compliance and flexibility but may fall short in performance for large-scale semantic searches. In contrast, specialized vector databases offer high-performance semantic search capabilities but come with increased operational complexity and potential cost implications. The decision should consider the specific scale and performance requirements of the onboarding tool, existing infrastructure, and the team's familiarity with each technology.\n",
      "### Architectural Decision Record (ADR) - Semantic Search Database Technology\n",
      "\n",
      "#### Context\n",
      "The development team is tasked with designing a new hire onboarding tool for a small-to-medium sized enterprise. The tool requires a semantic search feature. The database design must adhere to scalability, modularity, TOGAF principles, ACID compliance, and compatibility with UML/SysML for future diagramming. Two database approaches are under consideration: PostgreSQL with the `pgvector` extension and a specialized vector database.\n",
      "\n",
      "---\n",
      "\n",
      "### Approach 1: PostgreSQL with the `pgvector` Extension\n",
      "\n",
      "#### Suitability for Semantic Search\n",
      "- **Semantic Search Capability:** `pgvector` enables PostgreSQL to handle vector data, allowing it to perform semantic searches by comparing vector similarities.\n",
      "- **Integration:** Seamlessly integrates with existing PostgreSQL deployments, making it suitable for teams already using PostgreSQL.\n",
      "\n",
      "#### Operational Complexity\n",
      "- **Complexity:** Moderate complexity as teams may need to understand both relational and vector data handling within the same system.\n",
      "- **Maintenance:** Familiar PostgreSQL ecosystem reduces the learning curve and operational overhead.\n",
      "\n",
      "#### Cost\n",
      "- **Cost-Effective:** Utilizes existing PostgreSQL infrastructure, minimizing additional hardware or software investments.\n",
      "- **Open Source:** PostgreSQL and `pgvector` are open-source, reducing software licensing costs.\n",
      "\n",
      "#### Query Flexibility\n",
      "- **Flexibility:** Supports both traditional SQL queries and vector-based semantic queries, offering a versatile querying environment.\n",
      "- **Limitations:** Performance may degrade with complex semantic queries compared to dedicated vector databases.\n",
      "\n",
      "#### Scalability\n",
      "- **Scalability:** PostgreSQL is well-suited for moderate scalability, but handling large-scale vector data could require additional resources and optimizations.\n",
      "- **Modularity:** Supports modular enhancements through extensions and plugins, aligning with TOGAF principles.\n",
      "\n",
      "#### Strengths\n",
      "- **ACID Compliance:** Inherently supports ACID transactions, ensuring data integrity and consistency.\n",
      "- **UML/SysML Compatibility:** Well-documented schema design practices in PostgreSQL facilitate diagramming.\n",
      "\n",
      "#### Limitations\n",
      "- **Performance:** May not match the high performance of specialized vector databases for large-scale semantic search tasks.\n",
      "- **Resource Intensive:** Increased resource consumption when handling large vector datasets.\n",
      "\n",
      "---\n",
      "\n",
      "### Approach 2: Specialized Vector Database (e.g., ChromaDB, FAISS, Weaviate)\n",
      "\n",
      "#### Performance for Semantic Search\n",
      "- **High Performance:** Designed specifically for vector operations, providing superior performance in semantic search tasks.\n",
      "- **Optimization:** Tailored optimizations for vector similarity searches lead to faster query responses.\n",
      "\n",
      "#### Operational Complexity\n",
      "- **Complexity:** Higher complexity due to specialized nature; requires learning new technologies and operational paradigms.\n",
      "- **Maintenance:** Potentially higher maintenance as teams must manage an additional database system.\n",
      "\n",
      "#### Cost\n",
      "- **Variable Costs:** May involve additional costs for specialized infrastructure or commercial solutions.\n",
      "- **Open Source Options:** Some databases offer open-source versions, but enterprise features might be behind paywalls.\n",
      "\n",
      "#### Query Flexibility\n",
      "- **Specialized Queries:** Optimized for vector queries, but may lack the flexibility of traditional SQL queries.\n",
      "- **Integration:** Additional effort required to integrate with existing relational databases for comprehensive querying capabilities.\n",
      "\n",
      "#### Scalability\n",
      "- **Scalability:** Highly scalable for vector data, designed to efficiently handle large volumes of high-dimensional data.\n",
      "- **Modularity:** Supports modular integration with other systems via APIs, aligning with TOGAF principles.\n",
      "\n",
      "#### Advantages\n",
      "- **Performance:** Superior performance for large-scale vector search tasks.\n",
      "- **Specialization:** Purpose-built for semantic search, offering advanced features and optimizations.\n",
      "\n",
      "#### Drawbacks\n",
      "- **ACID Compliance:** Not all vector databases provide ACID compliance, posing challenges for data integrity.\n",
      "- **UML/SysML Compatibility:** May require additional effort to represent vector database architectures in UML/SysML.\n",
      "\n",
      "---\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Both approaches offer unique benefits and challenges. PostgreSQL with `pgvector` provides a cost-effective, integrated solution with strong ACID compliance and flexibility but may fall short in performance for large-scale semantic searches. In contrast, specialized vector databases offer high-performance semantic search capabilities but come with increased operational complexity and potential cost implications. The decision should consider the specific scale and performance requirements of the onboarding tool, existing infrastructure, and the team's familiarity with each technology.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to research database options.\n",
    "db_research_prompt = \"\"\"\n",
    "You are an unbiased research assistant with expertise in database architecture and semantic search technologies. Your task is to provide a balanced technical comparison for a software development team designing a new hire onboarding tool with a semantic search feature.\n",
    "\n",
    "### Context:\n",
    "The onboarding tool is intended for a small-to-medium sized enterprise application. The database design must adhere to the following principles:\n",
    "1. **Scalability:** Ensure the solution can handle increasing data volumes and user queries efficiently.\n",
    "2. **Modularity:** Support future enhancements, such as integrating additional data sources or features.\n",
    "3. **TOGAF Principles:** Align with architectural principles of modularity, scalability, and maintainability.\n",
    "4. **ACID Compliance:** Ensure data integrity, consistency, and reliability.\n",
    "5. **UML/SysML Compatibility:** Facilitate future diagramming and visualization of the database architecture.\n",
    "\n",
    "### Task:\n",
    "Compare and contrast the following two approaches:\n",
    "\n",
    "1. **Approach 1:** Using PostgreSQL with the `pgvector` extension.\n",
    "   - Evaluate its suitability for semantic search tasks.\n",
    "   - Discuss its operational complexity, cost, query flexibility, and scalability.\n",
    "   - Highlight its strengths and limitations in the context of the onboarding tool.\n",
    "\n",
    "2. **Approach 2:** Using a specialized, dedicated vector database (e.g., ChromaDB, FAISS, Weaviate).\n",
    "   - Assess its performance for semantic search use cases.\n",
    "   - Analyze its operational complexity, cost, query flexibility, and scalability.\n",
    "   - Identify its advantages and drawbacks for the given use case.\n",
    "\n",
    "### Output:\n",
    "Provide a detailed summary of the pros and cons for each approach. Ensure the analysis is unbiased and considers the specific requirements of the onboarding tool. The output should be structured and ready for inclusion in an Architectural Decision Record (ADR).\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n",
      "```markdown\n",
      "# Title: Use PostgreSQL with the pgvector Extension for Semantic Search\n",
      "\n",
      "**Status:** Accepted\n",
      "\n",
      "## Context\n",
      "The new hire onboarding tool for our small-to-medium sized enterprise requires an efficient semantic search feature. The architectural decision must align with key principles: scalability, modularity, TOGAF compliance, ACID compliance, and compatibility with UML/SysML for future diagramming.\n",
      "\n",
      "Two main approaches were considered: using PostgreSQL with the `pgvector` extension and implementing a specialized vector database. The PostgreSQL option was evaluated for its ability to handle semantic search through vector data comparisons, its seamless integration with existing deployments, and its cost-effective nature due to open-source availability. \n",
      "\n",
      "Our choice had to consider the operational complexity, cost implications, query flexibility, and scalability requirements, as well as the need for strong ACID compliance and UML/SysML compatibility to ensure the tool's integrity, reliability, and maintainability.\n",
      "\n",
      "## Decision\n",
      "We decided to use PostgreSQL with the `pgvector` extension for implementing the semantic search feature in the onboarding tool. The primary rationale for this decision includes:\n",
      "\n",
      "- **Integration:** The ability to integrate seamlessly with our existing PostgreSQL infrastructure, minimizing disruption and leveraging existing expertise.\n",
      "- **Cost-Effectiveness:** Utilizing open-source PostgreSQL and `pgvector` reduces software licensing costs and infrastructure investments.\n",
      "- **Flexibility:** Supports both traditional SQL and vector-based semantic queries, offering a versatile and familiar querying environment.\n",
      "- **ACID Compliance:** Ensures data integrity and consistency, which is crucial for maintaining reliable and accurate search results.\n",
      "- **Modularity and Scalability:** PostgreSQL's extension capabilities support modular enhancements and moderate scalability, aligning with TOGAF principles.\n",
      "\n",
      "## Consequences\n",
      "- **Positive Outcomes:** \n",
      "  - Cost reduction by leveraging existing PostgreSQL infrastructure.\n",
      "  - Streamlined operations due to minimized learning curve and operational overhead.\n",
      "  - Consistent data integrity and reliability through ACID compliance.\n",
      "  - Enhanced flexibility with support for both SQL and vector queries.\n",
      "\n",
      "- **Negative Outcomes:**\n",
      "  - Potential performance limitations when handling large-scale vector data compared to specialized vector databases.\n",
      "  - Increased resource consumption for complex semantic queries, requiring optimizations for scalability.\n",
      "\n",
      "## Notes\n",
      "Our decision to use PostgreSQL with `pgvector` aligns with our enterprise's current capabilities and future needs. We anticipate addressing potential performance limitations through resource optimization and scaling strategies as data volumes grow. Future considerations include monitoring the development of specialized vector databases to assess if a transition might be warranted as our requirements evolve.\n",
      "\n",
      "This ADR will be maintained in our version-controlled repository to ensure ongoing documentation of architectural decisions and facilitate future reviews and updates. Stakeholders are encouraged to provide feedback and discuss further enhancements as needed.\n",
      "```\n",
      "✅ Successfully saved artifact to: artifacts/adr_001_database_choice.md\n",
      "```markdown\n",
      "# Title: Use PostgreSQL with the pgvector Extension for Semantic Search\n",
      "\n",
      "**Status:** Accepted\n",
      "\n",
      "## Context\n",
      "The new hire onboarding tool for our small-to-medium sized enterprise requires an efficient semantic search feature. The architectural decision must align with key principles: scalability, modularity, TOGAF compliance, ACID compliance, and compatibility with UML/SysML for future diagramming.\n",
      "\n",
      "Two main approaches were considered: using PostgreSQL with the `pgvector` extension and implementing a specialized vector database. The PostgreSQL option was evaluated for its ability to handle semantic search through vector data comparisons, its seamless integration with existing deployments, and its cost-effective nature due to open-source availability. \n",
      "\n",
      "Our choice had to consider the operational complexity, cost implications, query flexibility, and scalability requirements, as well as the need for strong ACID compliance and UML/SysML compatibility to ensure the tool's integrity, reliability, and maintainability.\n",
      "\n",
      "## Decision\n",
      "We decided to use PostgreSQL with the `pgvector` extension for implementing the semantic search feature in the onboarding tool. The primary rationale for this decision includes:\n",
      "\n",
      "- **Integration:** The ability to integrate seamlessly with our existing PostgreSQL infrastructure, minimizing disruption and leveraging existing expertise.\n",
      "- **Cost-Effectiveness:** Utilizing open-source PostgreSQL and `pgvector` reduces software licensing costs and infrastructure investments.\n",
      "- **Flexibility:** Supports both traditional SQL and vector-based semantic queries, offering a versatile and familiar querying environment.\n",
      "- **ACID Compliance:** Ensures data integrity and consistency, which is crucial for maintaining reliable and accurate search results.\n",
      "- **Modularity and Scalability:** PostgreSQL's extension capabilities support modular enhancements and moderate scalability, aligning with TOGAF principles.\n",
      "\n",
      "## Consequences\n",
      "- **Positive Outcomes:** \n",
      "  - Cost reduction by leveraging existing PostgreSQL infrastructure.\n",
      "  - Streamlined operations due to minimized learning curve and operational overhead.\n",
      "  - Consistent data integrity and reliability through ACID compliance.\n",
      "  - Enhanced flexibility with support for both SQL and vector queries.\n",
      "\n",
      "- **Negative Outcomes:**\n",
      "  - Potential performance limitations when handling large-scale vector data compared to specialized vector databases.\n",
      "  - Increased resource consumption for complex semantic queries, requiring optimizations for scalability.\n",
      "\n",
      "## Notes\n",
      "Our decision to use PostgreSQL with `pgvector` aligns with our enterprise's current capabilities and future needs. We anticipate addressing potential performance limitations through resource optimization and scaling strategies as data volumes grow. Future considerations include monitoring the development of specialized vector databases to assess if a transition might be warranted as our requirements evolve.\n",
      "\n",
      "This ADR will be maintained in our version-controlled repository to ensure ongoing documentation of architectural decisions and facilitate future reviews and updates. Stakeholders are encouraged to provide feedback and discuss further enhancements as needed.\n",
      "```\n",
      "✅ Successfully saved artifact to: artifacts/adr_001_database_choice.md\n"
     ]
    }
   ],
   "source": [
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "# TODO: Write a prompt to synthesize the final ADR.\n",
    "synthesis_prompt = f\"\"\"\n",
    "You are a Staff Engineer responsible for documenting key architectural decisions for a new hire onboarding tool. Your task is to populate the provided ADR template to formally document the decision to **use PostgreSQL with the pgvector extension** for the semantic search feature.\n",
    "\n",
    "### Context:\n",
    "The onboarding tool is intended for a small-to-medium sized enterprise application. The architectural decision must adhere to the following principles:\n",
    "1. **Scalability:** Ensure the solution can handle increasing data volumes and user queries efficiently.\n",
    "2. **Modularity:** Support future enhancements, such as integrating additional data sources or features.\n",
    "3. **TOGAF Principles:** Align with architectural principles of modularity, scalability, and maintainability.\n",
    "4. **ACID Compliance:** Ensure data integrity, consistency, and reliability.\n",
    "5. **UML/SysML Compatibility:** Facilitate future diagramming and visualization of the database architecture.\n",
    "\n",
    "### Task:\n",
    "1. Use the provided ADR template to document the decision.\n",
    "2. Populate the 'Context' section with a summary of the problem, constraints, and forces influencing the decision, based on the research provided.\n",
    "3. Populate the 'Consequences' section with the expected benefits and potential drawbacks of the decision, ensuring a balanced and objective analysis.\n",
    "4. Ensure the ADR is complete, professional, and ready for review.\n",
    "\n",
    "--- ADR TEMPLATE ---\n",
    "{adr_template}\n",
    "--- END TEMPLATE ---\n",
    "\n",
    "--- RESEARCH CONTEXT ---\n",
    "{db_research_output}\n",
    "--- END CONTEXT ---\n",
    "\n",
    "The final ADR should be structured, thorough, and adhere to the specified principles.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\")\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
