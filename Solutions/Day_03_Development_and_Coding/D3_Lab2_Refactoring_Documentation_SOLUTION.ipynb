{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - Lab 2: Refactoring & Documentation (Solution)\n",
    "\n",
    "**Objective:** Use an LLM to refactor a complex Python function to improve its readability and maintainability, and then generate comprehensive, high-quality documentation for the project.\n",
    "\n",
    "**Introduction:**\n",
    "This solution notebook provides the complete prompts for the refactoring and documentation lab. It demonstrates how to guide an LLM to perform specific code quality improvements and generate structured documentation from multiple sources.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Code to Improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_code = \"\"\"\n",
    "def process_data(data, operation):\n",
    "    if operation == 'sum':\n",
    "        total = 0\n",
    "        for i in data:\n",
    "            total += i\n",
    "        return total\n",
    "    elif operation == 'average':\n",
    "        total = 0\n",
    "        for i in data:\n",
    "            total += i\n",
    "        return total / len(data)\n",
    "    elif operation == 'max':\n",
    "        max_val = data[0]\n",
    "        for i in data:\n",
    "            if i > max_val:\n",
    "                max_val = i\n",
    "        return max_val\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Refactoring the Code\n",
    "\n",
    "**Explanation:**\n",
    "This prompt is highly specific about the desired outcome. Instead of just saying \"improve this code,\" we give the LLM concrete principles to follow: apply the 'Single Responsibility Principle,' use built-in functions, and add type hints. This guidance transforms a vague request into a precise engineering task, leading to a much higher-quality output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Refactoring Code ---\n",
      "from typing import List, Union\n",
      "\n",
      "def calculate_sum(data: List[Union[int, float]]) -> Union[int, float]:\n",
      "    return sum(data)\n",
      "\n",
      "def calculate_average(data: List[Union[int, float]]) -> float:\n",
      "    return sum(data) / len(data) if data else 0.0\n",
      "\n",
      "def find_max(data: List[Union[int, float]]) -> Union[int, float]:\n",
      "    return max(data)\n",
      "\n",
      "def process_data(data: List[Union[int, float]], operation: str) -> Union[int, float]:\n",
      "    operations = {\n",
      "        'sum': calculate_sum,\n",
      "        'average': calculate_average,\n",
      "        'max': find_max,\n",
      "    }\n",
      "    if operation in operations:\n",
      "        return operations[operation](data)\n",
      "    raise ValueError(f\"Unsupported operation: {operation}\")\n"
     ]
    }
   ],
   "source": [
    "refactor_prompt = f\"\"\"\n",
    "You are a senior Python developer who writes clean, efficient, and maintainable code.\n",
    "\n",
    "Please refactor the following Python code. Apply the 'Single Responsibility Principle' by breaking the main function into smaller, more focused functions. Also, use modern Python features like built-in functions and add type hints.\n",
    "\n",
    "**Code to Refactor:**\n",
    "```python\n",
    "{bad_code}\n",
    "```\n",
    "\n",
    "Output only the refactored Python code.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Refactoring Code ---\")\n",
    "refactored_code = get_completion(refactor_prompt, client, model_name, api_provider)\n",
    "cleaned_code = clean_llm_output(refactored_code, language='python')\n",
    "print(cleaned_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Docstrings\n",
    "\n",
    "**Explanation:**\n",
    "This prompt builds on the previous step. We provide the newly refactored code and ask for another specific, structured output: Google-style docstrings. LLMs are exceptionally good at this type of structured text generation. They can parse the function signature to identify the arguments and return types and generate well-formatted, descriptive documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Docstrings ---\n",
      "from typing import List, Union\n",
      "\n",
      "def calculate_sum(data: List[Union[int, float]]) -> Union[int, float]:\n",
      "    \"\"\"Calculate the sum of a list of numbers.\n",
      "\n",
      "    Args:\n",
      "        data (List[Union[int, float]]): A list of integers and/or floats to be summed.\n",
      "\n",
      "    Returns:\n",
      "        Union[int, float]: The sum of the numbers in the list.\n",
      "    \"\"\"\n",
      "    return sum(data)\n",
      "\n",
      "def calculate_average(data: List[Union[int, float]]) -> float:\n",
      "    \"\"\"Calculate the average of a list of numbers.\n",
      "\n",
      "    Args:\n",
      "        data (List[Union[int, float]]): A list of integers and/or floats to calculate the average.\n",
      "\n",
      "    Returns:\n",
      "        float: The average of the numbers in the list. Returns 0.0 if the list is empty.\n",
      "    \"\"\"\n",
      "    return sum(data) / len(data) if data else 0.0\n",
      "\n",
      "def find_max(data: List[Union[int, float]]) -> Union[int, float]:\n",
      "    \"\"\"Find the maximum number in a list of numbers.\n",
      "\n",
      "    Args:\n",
      "        data (List[Union[int, float]]): A list of integers and/or floats to find the maximum value.\n",
      "\n",
      "    Returns:\n",
      "        Union[int, float]: The maximum number in the list.\n",
      "    \"\"\"\n",
      "    return max(data)\n",
      "\n",
      "def process_data(data: List[Union[int, float]], operation: str) -> Union[int, float]:\n",
      "    \"\"\"Process a list of numbers with a specified operation.\n",
      "\n",
      "    Args:\n",
      "        data (List[Union[int, float]]): A list of integers and/or floats to be processed.\n",
      "        operation (str): The operation to perform on the data. Supported operations are 'sum', 'average', and 'max'.\n",
      "\n",
      "    Returns:\n",
      "        Union[int, float]: The result of the operation applied to the list.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the operation is not supported.\n",
      "    \"\"\"\n",
      "    operations = {\n",
      "        'sum': calculate_sum,\n",
      "        'average': calculate_average,\n",
      "        'max': find_max,\n",
      "    }\n",
      "    if operation in operations:\n",
      "        return operations[operation](data)\n",
      "    raise ValueError(f\"Unsupported operation: {operation}\")\n"
     ]
    }
   ],
   "source": [
    "docstring_prompt = f\"\"\"\n",
    "You are a Python developer who writes excellent documentation.\n",
    "\n",
    "Add Google-style docstrings to the following Python code. Each docstring should include a description of the function, its arguments (Args:), and what it returns (Returns:).\n",
    "\n",
    "**Python Code:**\n",
    "```python\n",
    "{cleaned_code}\n",
    "```\n",
    "\n",
    "Output the complete Python code with the added docstrings.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Docstrings ---\")\n",
    "code_with_docstrings = get_completion(docstring_prompt, client, model_name, api_provider)\n",
    "cleaned_code_with_docstrings = clean_llm_output(code_with_docstrings, language='python')\n",
    "print(cleaned_code_with_docstrings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Generating a Project README\n",
    "\n",
    "**Explanation:**\n",
    "Using an LLM to generate docstrings and a README is a massive productivity boost. It excels at this structured writing task, freeing up the developer to focus on complex logic while still ensuring the project is well-documented and easy for others to understand. This prompt is a synthesis task. We provide the LLM with both high-level requirements (the PRD) and low-level implementation details (the API source code). The LLM's job is to merge these two sources of information into a single, comprehensive `README.md` file, complete with overviews, feature lists, and practical `curl` examples derived from the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Project README ---\n",
      "# Employee Onboarding Management Platform\n",
      "\n",
      "## Overview\n",
      "\n",
      "The Employee Onboarding Management Platform is a comprehensive digital solution designed to streamline and enhance the new hire experience. It provides managers and HR teams with powerful tools to track, customize, and optimize the onboarding process. By centralizing tasks, training materials, progress tracking, and feedback mechanisms into a single, intuitive interface, this platform aims to accelerate time-to-productivity for new hires while reducing administrative overhead for HR teams and managers.\n",
      "\n",
      "## Features\n",
      "\n",
      "- **Interactive Task Management**: New hires can track and complete essential tasks via an interactive checklist.\n",
      "- **Progress Monitoring**: HR managers can track onboarding progress and receive notifications about any delays.\n",
      "- **Role-Specific Task Assignment**: Team leaders can assign tasks specific to their team's needs.\n",
      "- **Self-Paced Learning System**: New hires have access to training modules to learn at their own pace.\n",
      "- **Continuous Improvement Framework**: HR managers can gather feedback from new hires to improve the onboarding process.\n",
      "\n",
      "## API Endpoints\n",
      "\n",
      "### Create a User\n",
      "\n",
      "- **Endpoint**: `/users/`\n",
      "- **Method**: `POST`\n",
      "- **Description**: Create a new user with an email, name, and role.\n",
      "- **Request Body**:\n",
      "  ```json\n",
      "  {\n",
      "    \"email\": \"sarah@example.com\",\n",
      "    \"name\": \"Sarah\",\n",
      "    \"role\": \"New Hire\"\n",
      "  }\n",
      "  ```\n",
      "- **Curl Example**:\n",
      "  ```bash\n",
      "  curl -X POST \"http://localhost:8000/users/\" -H \"Content-Type: application/json\" -d '{\"email\":\"sarah@example.com\",\"name\":\"Sarah\",\"role\":\"New Hire\"}'\n",
      "  ```\n",
      "\n",
      "### Read Users\n",
      "\n",
      "- **Endpoint**: `/users/`\n",
      "- **Method**: `GET`\n",
      "- **Description**: Retrieve a list of users with pagination support.\n",
      "- **Parameters**:\n",
      "  - `skip` (optional): Number of records to skip (default is 0).\n",
      "  - `limit` (optional): Maximum number of records to return (default is 100).\n",
      "- **Curl Example**:\n",
      "  ```bash\n",
      "  curl -X GET \"http://localhost:8000/users/\"\n",
      "  ```\n",
      "\n",
      "### Read a User\n",
      "\n",
      "- **Endpoint**: `/users/{user_id}`\n",
      "- **Method**: `GET`\n",
      "- **Description**: Retrieve a specific user by ID.\n",
      "- **Curl Example**:\n",
      "  ```bash\n",
      "  curl -X GET \"http://localhost:8000/users/1\"\n",
      "  ```\n",
      "\n",
      "## Setup and Installation\n",
      "\n",
      "To run the FastAPI app, follow these steps:\n",
      "\n",
      "1. **Clone the Repository**:\n",
      "   ```bash\n",
      "   git clone <repository-url>\n",
      "   cd <repository-directory>\n",
      "   ```\n",
      "\n",
      "2. **Create a Virtual Environment** (optional but recommended):\n",
      "   ```bash\n",
      "   python -m venv venv\n",
      "   source venv/bin/activate   # On Windows use `venv\\Scripts\\activate`\n",
      "   ```\n",
      "\n",
      "3. **Install Dependencies**:\n",
      "   ```bash\n",
      "   pip install fastapi sqlalchemy uvicorn pydantic\n",
      "   ```\n",
      "\n",
      "4. **Run the FastAPI Application**:\n",
      "   ```bash\n",
      "   uvicorn main:app --reload\n",
      "   ```\n",
      "\n",
      "   The application will be available at `http://localhost:8000`.\n",
      "\n",
      "This README provides a concise overview of the Employee Onboarding Management Platform's purpose, features, API endpoints, and setup instructions. For more detailed information, please refer to the project's full documentation.\n",
      "âœ… Successfully saved artifact to: README.md\n"
     ]
    }
   ],
   "source": [
    "# Load the necessary context files\n",
    "prd_content = load_artifact(\"artifacts/day1_prd.md\")\n",
    "api_code = load_artifact(\"app/main.py\")\n",
    "\n",
    "readme_prompt = f\"\"\"\n",
    "You are a technical writer creating a README.md file for a new open-source project.\n",
    "\n",
    "Use the provided Product Requirements Document (PRD) for high-level context and the FastAPI source code for technical details.\n",
    "\n",
    "**PRD Context:**\n",
    "<prd>\n",
    "{prd_content}\n",
    "</prd>\n",
    "\n",
    "**API Source Code:**\n",
    "<code>\n",
    "{api_code}\n",
    "</code>\n",
    "\n",
    "Generate a complete README.md file with the following sections:\n",
    "- Project Title\n",
    "- Overview (Summarize the project's purpose from the PRD)\n",
    "- Features\n",
    "- API Endpoints (List the available endpoints and provide a `curl` example for each one, including the POST request with a JSON body)\n",
    "- Setup and Installation (Provide basic instructions on how to run the FastAPI app with uvicorn)\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Project README ---\")\n",
    "if prd_content and api_code:\n",
    "    readme_content = get_completion(readme_prompt, client, model_name, api_provider)\n",
    "    cleaned_readme = clean_llm_output(readme_content, language='markdown')\n",
    "    print(cleaned_readme)\n",
    "    save_artifact(cleaned_readme, \"README.md\")\n",
    "else:\n",
    "    print(\"Skipping README generation because PRD or API code is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to perform two of the most valuable code quality tasks: refactoring and documentation. You've seen how AI can help transform messy code into a clean, maintainable structure and how it can generate comprehensive documentation from high-level project artifacts and source code. These skills are a massive productivity multiplier for any development team.\n",
    "\n",
    "> **Key Takeaway:** LLMs excel at understanding and generating structured text, whether that structure is code or documentation. Providing a clear 'before' state (the bad code) and a clear goal (the refactoring principles) allows the AI to perform complex code transformation and documentation tasks efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
