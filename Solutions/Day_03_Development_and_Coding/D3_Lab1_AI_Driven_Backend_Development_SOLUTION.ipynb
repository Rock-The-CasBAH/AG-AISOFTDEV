{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - Lab 1: AI-Driven Backend Development (Solution)\n",
    "\n",
    "**Objective:** Generate a complete FastAPI backend application, including Pydantic and SQLAlchemy models, and then perform the critical engineering task of integrating the generated code with the live SQLite database created on Day 2.\n",
    "\n",
    "**Introduction:**\n",
    "This solution notebook provides the complete code and prompts for generating and assembling the database-connected API. It highlights the workflow of generating components separately and then integrating them, a common pattern in AI-assisted development.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Explanation:**\n",
    "We load our `schema.sql` artifact, which will be the primary context for our code generation prompts. Having the database schema is essential for the LLM to accurately generate models (both Pydantic and SQLAlchemy) and endpoints that match our data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'huggingface' with model 'meta-llama/Llama-4-Scout-17B-16E-Instruct'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/armando/Documents/Github/AG-AISOFTDEV/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, recommended_models_table\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-4-Scout-17B-16E-Instruct\")\n",
    "\n",
    "# Load the SQL schema from Day 2\n",
    "sql_schema = load_artifact(\"artifacts/schema.sql\")\n",
    "if not sql_schema:\n",
    "    print(\"Warning: Could not load schema.sql. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Model | Provider | Vision | Image Gen | Audio Transcription | Context Window | Max Output Tokens |\n",
       "|---|---|---|---|---|---|---|\n",
       "| claude-opus-4-1-20250805 | anthropic | ✅ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| claude-opus-4-20250514 | anthropic | ✅ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| claude-sonnet-4-20250514 | anthropic | ✅ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| codex-mini | openai | ✅ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| dall-e-3 | openai | ❌ | ✅ | ❌ | - | - |\n",
       "| deepseek-ai/DeepSeek-V3 | huggingface | ❌ | ❌ | ❌ | 128,000 | 100,000 |\n",
       "| deepseek-ai/DeepSeek-V3-Small | huggingface | ❌ | ❌ | ❌ | 128,000 | 100,000 |\n",
       "| deepseek-ai/DeepSeek-VL2 | huggingface | ✅ | ❌ | ❌ | 32,000 | 8,000 |\n",
       "| deepseek-ai/DeepSeek-VL2-Small | huggingface | ✅ | ❌ | ❌ | 32,000 | 8,000 |\n",
       "| deepseek-ai/DeepSeek-VL2-Tiny | huggingface | ✅ | ❌ | ❌ | 32,000 | 8,000 |\n",
       "| deepseek-ai/Janus-Pro-7B | huggingface | ✅ | ❌ | ❌ | 8,192 | 2,048 |\n",
       "| gemini-2.0-flash | google | ✅ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gemini-2.0-flash-lite | google | ✅ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gemini-2.0-flash-live-001 | google | ✅ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gemini-2.5-flash | google | ✅ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-flash-image-preview | google | ✅ | ✅ | ❌ | 32,768 | 32,768 |\n",
       "| gemini-2.5-flash-lite | google | ✅ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-pro | google | ✅ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-deep-think | google | ✅ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| gemini-live-2.5-flash-preview | google | ✅ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gemini-veo-3 | google | ✅ | ❌ | ❌ | - | - |\n",
       "| google-cloud/speech-to-text/latest_long | google | ❌ | ❌ | ✅ | - | - |\n",
       "| google-cloud/speech-to-text/latest_short | google | ❌ | ❌ | ✅ | - | - |\n",
       "| gpt-4.1 | openai | ✅ | ❌ | ❌ | 1,000,000 | 32,000 |\n",
       "| gpt-4.1-mini | openai | ✅ | ❌ | ❌ | 1,000,000 | 32,000 |\n",
       "| gpt-4.1-nano | openai | ✅ | ❌ | ❌ | 1,000,000 | 32,000 |\n",
       "| gpt-4.5 | openai | ✅ | ❌ | ❌ | 128,000 | 16,384 |\n",
       "| gpt-4o | openai | ✅ | ❌ | ❌ | 128,000 | 16,384 |\n",
       "| gpt-4o-mini | openai | ✅ | ❌ | ❌ | 128,000 | 16,384 |\n",
       "| gpt-5-2025-08-07 | openai | ✅ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-5-mini-2025-08-07 | openai | ✅ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-5-nano-2025-08-07 | openai | ✅ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-image-1 | openai | ✅ | ✅ | ❌ | - | - |\n",
       "| imagen-3.0-generate-002 | google | ❌ | ✅ | ❌ | - | - |\n",
       "| imagen-4.0-generate-001 | google | ❌ | ✅ | ❌ | 480 | - |\n",
       "| meta-llama/Llama-3.3-70B-Instruct | huggingface | ❌ | ❌ | ❌ | 4,096 | 1,024 |\n",
       "| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ✅ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ✅ | ❌ | ❌ | 10,000,000 | 100,000 |\n",
       "| mistralai/Mistral-7B-Instruct-v0.3 | huggingface | ❌ | ❌ | ❌ | 32,768 | 8,192 |\n",
       "| o3 | openai | ✅ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| o4-mini | openai | ✅ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3 | huggingface | ❌ | ❌ | ❌ | 4,096 | 1,024 |\n",
       "| tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5 | huggingface | ❌ | ❌ | ❌ | 4,096 | 1,024 |\n",
       "| whisper-1 | openai | ❌ | ❌ | ✅ | - | - |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'| Model | Provider | Vision | Image Gen | Audio Transcription | Context Window | Max Output Tokens |\\n|---|---|---|---|---|---|---|\\n| claude-opus-4-1-20250805 | anthropic | ✅ | ❌ | ❌ | 200,000 | 100,000 |\\n| claude-opus-4-20250514 | anthropic | ✅ | ❌ | ❌ | 200,000 | 100,000 |\\n| claude-sonnet-4-20250514 | anthropic | ✅ | ❌ | ❌ | 1,000,000 | 100,000 |\\n| codex-mini | openai | ✅ | ❌ | ❌ | 200,000 | 100,000 |\\n| dall-e-3 | openai | ❌ | ✅ | ❌ | - | - |\\n| deepseek-ai/DeepSeek-V3 | huggingface | ❌ | ❌ | ❌ | 128,000 | 100,000 |\\n| deepseek-ai/DeepSeek-V3-Small | huggingface | ❌ | ❌ | ❌ | 128,000 | 100,000 |\\n| deepseek-ai/DeepSeek-VL2 | huggingface | ✅ | ❌ | ❌ | 32,000 | 8,000 |\\n| deepseek-ai/DeepSeek-VL2-Small | huggingface | ✅ | ❌ | ❌ | 32,000 | 8,000 |\\n| deepseek-ai/DeepSeek-VL2-Tiny | huggingface | ✅ | ❌ | ❌ | 32,000 | 8,000 |\\n| deepseek-ai/Janus-Pro-7B | huggingface | ✅ | ❌ | ❌ | 8,192 | 2,048 |\\n| gemini-2.0-flash | google | ✅ | ❌ | ❌ | 1,048,576 | 8,192 |\\n| gemini-2.0-flash-lite | google | ✅ | ❌ | ❌ | 1,048,576 | 8,192 |\\n| gemini-2.0-flash-live-001 | google | ✅ | ❌ | ❌ | 1,048,576 | 8,192 |\\n| gemini-2.5-flash | google | ✅ | ❌ | ❌ | 1,048,576 | 65,536 |\\n| gemini-2.5-flash-image-preview | google | ✅ | ✅ | ❌ | 32,768 | 32,768 |\\n| gemini-2.5-flash-lite | google | ✅ | ❌ | ❌ | 1,048,576 | 65,536 |\\n| gemini-2.5-pro | google | ✅ | ❌ | ❌ | 1,048,576 | 65,536 |\\n| gemini-deep-think | google | ✅ | ❌ | ❌ | 1,000,000 | 100,000 |\\n| gemini-live-2.5-flash-preview | google | ✅ | ❌ | ❌ | 1,048,576 | 8,192 |\\n| gemini-veo-3 | google | ✅ | ❌ | ❌ | - | - |\\n| google-cloud/speech-to-text/latest_long | google | ❌ | ❌ | ✅ | - | - |\\n| google-cloud/speech-to-text/latest_short | google | ❌ | ❌ | ✅ | - | - |\\n| gpt-4.1 | openai | ✅ | ❌ | ❌ | 1,000,000 | 32,000 |\\n| gpt-4.1-mini | openai | ✅ | ❌ | ❌ | 1,000,000 | 32,000 |\\n| gpt-4.1-nano | openai | ✅ | ❌ | ❌ | 1,000,000 | 32,000 |\\n| gpt-4.5 | openai | ✅ | ❌ | ❌ | 128,000 | 16,384 |\\n| gpt-4o | openai | ✅ | ❌ | ❌ | 128,000 | 16,384 |\\n| gpt-4o-mini | openai | ✅ | ❌ | ❌ | 128,000 | 16,384 |\\n| gpt-5-2025-08-07 | openai | ✅ | ❌ | ❌ | 400,000 | 128,000 |\\n| gpt-5-mini-2025-08-07 | openai | ✅ | ❌ | ❌ | 400,000 | 128,000 |\\n| gpt-5-nano-2025-08-07 | openai | ✅ | ❌ | ❌ | 400,000 | 128,000 |\\n| gpt-image-1 | openai | ✅ | ✅ | ❌ | - | - |\\n| imagen-3.0-generate-002 | google | ❌ | ✅ | ❌ | - | - |\\n| imagen-4.0-generate-001 | google | ❌ | ✅ | ❌ | 480 | - |\\n| meta-llama/Llama-3.3-70B-Instruct | huggingface | ❌ | ❌ | ❌ | 4,096 | 1,024 |\\n| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ✅ | ❌ | ❌ | 1,000,000 | 100,000 |\\n| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ✅ | ❌ | ❌ | 10,000,000 | 100,000 |\\n| mistralai/Mistral-7B-Instruct-v0.3 | huggingface | ❌ | ❌ | ❌ | 32,768 | 8,192 |\\n| o3 | openai | ✅ | ❌ | ❌ | 200,000 | 100,000 |\\n| o4-mini | openai | ✅ | ❌ | ❌ | 200,000 | 100,000 |\\n| tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3 | huggingface | ❌ | ❌ | ❌ | 4,096 | 1,024 |\\n| tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5 | huggingface | ❌ | ❌ | ❌ | 4,096 | 1,024 |\\n| whisper-1 | openai | ❌ | ❌ | ✅ | - | - |'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_models_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating Code with In-Memory Logic\n",
    "\n",
    "**Explanation:**\n",
    "This prompt generates a fully functional but simplified version of our application. By asking for an in-memory database, we allow the LLM to focus on generating the correct API structure, endpoints, and Pydantic models without the added complexity of database integration code. This gives us a clean, working baseline that we can build upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating FastAPI app with in-memory database ---\n",
      "✅ Successfully saved artifact to: app/main_in_memory.py\n",
      "Saved in-memory API to app/main_in_memory.py\n"
     ]
    }
   ],
   "source": [
    "in_memory_api_prompt = f\"\"\"\n",
    "You are a senior Python developer creating a FastAPI application for a new hire onboarding tool.\n",
    "\n",
    "Based on the following SQL schema, generate a single Python script for a `main.py` file that includes:\n",
    "1.  All necessary FastAPI imports.\n",
    "2.  Pydantic models for creating and reading `User` resources. Include fields for `id`, `name`, `email`, and `role`.\n",
    "3.  A simple in-memory list to act as a fake database for users.\n",
    "4.  Complete FastAPI CRUD endpoints for the `/users` path (POST, GET all, GET by ID).\n",
    "5.  The endpoints should perform their logic on the in-memory list.\n",
    "\n",
    "**SQL Schema Context:**\n",
    "```sql\n",
    "{sql_schema}\n",
    "```\n",
    "\n",
    "Output only the raw Python code.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating FastAPI app with in-memory database ---\")\n",
    "if sql_schema:\n",
    "    generated_api_code = get_completion(in_memory_api_prompt, client, model_name, api_provider)\n",
    "    cleaned_code = clean_llm_output(generated_api_code, language='python')\n",
    "    # Save this code to a temporary reference file\n",
    "    save_artifact(cleaned_code, \"app/main_in_memory.py\")\n",
    "    print(\"Saved in-memory API to app/main_in_memory.py\")\n",
    "else:\n",
    "    print(\"Skipping API generation because schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Database Models and Session Code\n",
    "\n",
    "**Explanation:**\n",
    "This prompt is highly specific. It asks for the two key components needed for database connectivity in a modern Python application: the ORM (Object-Relational Mapping) models and the session management code. \n",
    "-   **SQLAlchemy Models:** These classes map our Python objects directly to the tables in our database, allowing us to work with Python code instead of raw SQL.\n",
    "-   **Session Management:** This is the standard FastAPI pattern for handling database connections. The `get_db` function is a dependency that ensures each API request gets a database session and that the session is properly closed afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating SQLAlchemy Models and Session Code ---\n",
      "\n",
      "--- Generated Database Code ---\n",
      "### SQLAlchemy Models\n",
      "```python\n",
      "from sqlalchemy import Column, Integer, String, Date, Boolean, ForeignKey, Enum, Text, TIMESTAMP, CheckConstraint\n",
      "from sqlalchemy.orm import relationship\n",
      "from sqlalchemy.ext.declarative import declarative_base\n",
      "\n",
      "Base = declarative_base()\n",
      "\n",
      "class User(Base):\n",
      "    __tablename__ = 'users'\n",
      "    \n",
      "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
      "    name = Column(String, nullable=False)\n",
      "    email = Column(String, nullable=False, unique=True)\n",
      "    role = Column(String, nullable=False)\n",
      "    department = Column(String)\n",
      "    location = Column(String)\n",
      "    hire_date = Column(Date)\n",
      "    manager_id = Column(Integer, ForeignKey('users.id'))\n",
      "    created_at = Column(TIMESTAMP, default=lambda: None)\n",
      "    updated_at = Column(TIMESTAMP, default=lambda: None, onupdate=lambda: None)\n",
      "\n",
      "    manager = relationship('User', remote_side=[id], backref='team_members')\n",
      "    onboarding_tasks = relationship('OnboardingTask', backref='assignee')\n",
      "    assigned_tasks = relationship('OnboardingTask', backref='assigner', remote_side=[id])\n",
      "    training_progress = relationship('UserTrainingProgress', backref='user')\n",
      "    task_notifications = relationship('TaskNotification', backref='user')\n",
      "\n",
      "    __table_args__ = (\n",
      "        CheckConstraint('role IN (\\'New Hire\\', \\'Manager\\', \\'HR Specialist\\')', name='role_check'),\n",
      "    )\n",
      "\n",
      "\n",
      "class OnboardingTask(Base):\n",
      "    __tablename__ = 'onboarding_tasks'\n",
      "    \n",
      "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
      "    user_id = Column(Integer, ForeignKey('users.id'), nullable=False)\n",
      "    task_template_id = Column(Integer, ForeignKey('task_templates.id'))\n",
      "    title = Column(String, nullable=False)\n",
      "    description = Column(Text)\n",
      "    due_date = Column(Date)\n",
      "    status = Column(String, nullable=False, default='Pending')\n",
      "    completed_at = Column(TIMESTAMP)\n",
      "    priority = Column(String, default='Medium')\n",
      "    assigned_by = Column(Integer, ForeignKey('users.id'))\n",
      "    created_at = Column(TIMESTAMP, default=lambda: None)\n",
      "    updated_at = Column(TIMESTAMP, default=lambda: None, onupdate=lambda: None)\n",
      "\n",
      "    task_template = relationship('TaskTemplate', backref='onboarding_tasks')\n",
      "    notifications = relationship('TaskNotification', backref='task')\n",
      "\n",
      "    __table_args__ = (\n",
      "        CheckConstraint('status IN (\\'Pending\\', \\'In Progress\\', \\'Completed\\', \\'Overdue\\')', name='status_check'),\n",
      "        CheckConstraint('priority IN (\\'Low\\', \\'Medium\\', \\'High\\')', name='priority_check'),\n",
      "    )\n",
      "```\n",
      "\n",
      "### Database Session Management\n",
      "```python\n",
      "from fastapi import Depends\n",
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy.orm import sessionmaker\n",
      "from sqlalchemy.ext.declarative import declarative_base\n",
      "\n",
      "SQLALCHEMY_DATABASE_URL = \"sqlite:///onboarding.db\"\n",
      "\n",
      "engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
      "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
      "\n",
      "Base.metadata.create_all(engine)\n",
      "\n",
      "def get_db():\n",
      "    db = SessionLocal()\n",
      "    try:\n",
      "        yield db\n",
      "    finally:\n",
      "        db.close()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "db_code_prompt = f\"\"\"\n",
    "You are a Python expert specializing in FastAPI and SQLAlchemy.\n",
    "\n",
    "Based on the provided SQL schema, generate the necessary Python code to connect a FastAPI application to a SQLite database named 'onboarding.db'.\n",
    "\n",
    "**SQL Schema Context:**\n",
    "```sql\n",
    "{sql_schema}\n",
    "```\n",
    "\n",
    "Please provide two separate, well-commented code blocks:\n",
    "\n",
    "1.  **SQLAlchemy Models:** Create the Python classes that map to the `users` and `onboarding_tasks` tables.\n",
    "2.  **Database Session Management:** Provide the standard boilerplate code for creating the SQLAlchemy engine, the `SessionLocal` class, and the `get_db` dependency for FastAPI.\n",
    "\n",
    "Only output the raw Python code.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQLAlchemy Models and Session Code ---\")\n",
    "if sql_schema:\n",
    "    generated_db_code = get_completion(db_code_prompt, client, model_name, api_provider)\n",
    "    print(\"\\n--- Generated Database Code ---\")\n",
    "    print(generated_db_code)\n",
    "else:\n",
    "    print(\"Skipping DB code generation because schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Integrating Live Database Logic\n",
    "\n",
    "**Explanation:**\n",
    "This final code represents the crucial role of the developer in an AI-assisted workflow. The AI provided the components (Pydantic models, SQLAlchemy models, endpoint structure), but the developer is responsible for the final integration, ensuring all the pieces work together seamlessly. This involves combining the generated code blocks and replacing the in-memory list operations with live SQLAlchemy database calls (`db.add`, `db.query`, `db.commit`, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Integrated API Code for app/main.py ---\n",
      "from fastapi import FastAPI, Depends, HTTPException\n",
      "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Text, Date\n",
      "from sqlalchemy.ext.declarative import declarative_base\n",
      "from sqlalchemy.orm import sessionmaker, Session, relationship\n",
      "from pydantic import BaseModel\n",
      "from typing import List, Optional\n",
      "\n",
      "# --- SQLAlchemy Setup ---\n",
      "SQLALCHEMY_DATABASE_URL = \"sqlite:///./artifacts/onboarding.db\"\n",
      "engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False})\n",
      "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
      "Base = declarative_base()\n",
      "\n",
      "# --- SQLAlchemy Models ---\n",
      "class User(Base):\n",
      "    __tablename__ = 'users'\n",
      "    id = Column(Integer, primary_key=True, index=True)\n",
      "    name = Column(String, index=True)\n",
      "    email = Column(String, unique=True, index=True)\n",
      "    role = Column(String)\n",
      "    tasks = relationship(\"OnboardingTask\", back_populates=\"owner\")\n",
      "\n",
      "class OnboardingTask(Base):\n",
      "    __tablename__ = 'onboarding_tasks'\n",
      "    id = Column(Integer, primary_key=True, index=True)\n",
      "    title = Column(String, index=True)\n",
      "    description = Column(Text)\n",
      "    due_date = Column(Date)\n",
      "    status = Column(String, default='Pending')\n",
      "    user_id = Column(Integer, ForeignKey('users.id'))\n",
      "    owner = relationship(\"User\", back_populates=\"tasks\")\n",
      "\n",
      "# Create the database tables\n",
      "Base.metadata.create_all(bind=engine)\n",
      "\n",
      "# --- Pydantic Models ---\n",
      "class UserBase(BaseModel):\n",
      "    email: str\n",
      "    name: str\n",
      "    role: str\n",
      "\n",
      "class UserCreate(UserBase):\n",
      "    pass\n",
      "\n",
      "class UserSchema(UserBase):\n",
      "    id: int\n",
      "    class Config:\n",
      "        orm_mode = True\n",
      "\n",
      "# --- FastAPI App ---\n",
      "app = FastAPI()\n",
      "\n",
      "# --- Dependency ---\n",
      "def get_db():\n",
      "    db = SessionLocal()\n",
      "    try:\n",
      "        yield db\n",
      "    finally:\n",
      "        db.close()\n",
      "\n",
      "# --- API Endpoints ---\n",
      "@app.post(\"/users/\", response_model=UserSchema)\n",
      "def create_user(user: UserCreate, db: Session = Depends(get_db)):\n",
      "    db_user = db.query(User).filter(User.email == user.email).first()\n",
      "    if db_user:\n",
      "        raise HTTPException(status_code=400, detail=\"Email already registered\")\n",
      "    db_user = User(**user.dict())\n",
      "    db.add(db_user)\n",
      "    db.commit()\n",
      "    db.refresh(db_user)\n",
      "    return db_user\n",
      "\n",
      "@app.get(\"/users/\", response_model=List[UserSchema])\n",
      "def read_users(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):\n",
      "    users = db.query(User).offset(skip).limit(limit).all()\n",
      "    return users\n",
      "\n",
      "@app.get(\"/users/{user_id}\", response_model=UserSchema)\n",
      "def read_user(user_id: int, db: Session = Depends(get_db)):\n",
      "    db_user = db.query(User).filter(User.id == user_id).first()\n",
      "    if db_user is None:\n",
      "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
      "    return db_user\n",
      "\n",
      "✅ Successfully saved artifact to: app/main.py\n"
     ]
    }
   ],
   "source": [
    "# This block contains the complete, final code for app/main.py after manual integration.\n",
    "final_api_code = \"\"\"from fastapi import FastAPI, Depends, HTTPException\n",
    "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Text, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, Session, relationship\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "# --- SQLAlchemy Setup ---\n",
    "SQLALCHEMY_DATABASE_URL = \"sqlite:///./artifacts/onboarding.db\"\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False})\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "Base = declarative_base()\n",
    "\n",
    "# --- SQLAlchemy Models ---\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    name = Column(String, index=True)\n",
    "    email = Column(String, unique=True, index=True)\n",
    "    role = Column(String)\n",
    "    tasks = relationship(\"OnboardingTask\", back_populates=\"owner\")\n",
    "\n",
    "class OnboardingTask(Base):\n",
    "    __tablename__ = 'onboarding_tasks'\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    title = Column(String, index=True)\n",
    "    description = Column(Text)\n",
    "    due_date = Column(Date)\n",
    "    status = Column(String, default='Pending')\n",
    "    user_id = Column(Integer, ForeignKey('users.id'))\n",
    "    owner = relationship(\"User\", back_populates=\"tasks\")\n",
    "\n",
    "# Create the database tables\n",
    "Base.metadata.create_all(bind=engine)\n",
    "\n",
    "# --- Pydantic Models ---\n",
    "class UserBase(BaseModel):\n",
    "    email: str\n",
    "    name: str\n",
    "    role: str\n",
    "\n",
    "class UserCreate(UserBase):\n",
    "    pass\n",
    "\n",
    "class UserSchema(UserBase):\n",
    "    id: int\n",
    "    class Config:\n",
    "        orm_mode = True\n",
    "\n",
    "# --- FastAPI App ---\n",
    "app = FastAPI()\n",
    "\n",
    "# --- Dependency ---\n",
    "def get_db():\n",
    "    db = SessionLocal()\n",
    "    try:\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "# --- API Endpoints ---\n",
    "@app.post(\"/users/\", response_model=UserSchema)\n",
    "def create_user(user: UserCreate, db: Session = Depends(get_db)):\n",
    "    db_user = db.query(User).filter(User.email == user.email).first()\n",
    "    if db_user:\n",
    "        raise HTTPException(status_code=400, detail=\"Email already registered\")\n",
    "    db_user = User(**user.dict())\n",
    "    db.add(db_user)\n",
    "    db.commit()\n",
    "    db.refresh(db_user)\n",
    "    return db_user\n",
    "\n",
    "@app.get(\"/users/\", response_model=List[UserSchema])\n",
    "def read_users(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):\n",
    "    users = db.query(User).offset(skip).limit(limit).all()\n",
    "    return users\n",
    "\n",
    "@app.get(\"/users/{user_id}\", response_model=UserSchema)\n",
    "def read_user(user_id: int, db: Session = Depends(get_db)):\n",
    "    db_user = db.query(User).filter(User.id == user_id).first()\n",
    "    if db_user is None:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    return db_user\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Final Integrated API Code for app/main.py ---\")\n",
    "print(final_api_code)\n",
    "save_artifact(final_api_code, \"app/main.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have successfully generated and assembled a complete, database-connected backend API. You used an LLM to generate the boilerplate for both the API endpoints and the database models, and then performed the crucial engineering task of integrating them. You now have a working `main.py` file in your `app` directory that can create, read, update, and delete data in a live database. In the next lab, we will write a comprehensive test suite for this API.\n",
    "\n",
    "> **Key Takeaway:** AI excels at generating boilerplate code (like models and endpoint structures), but the developer's critical role is in the final integration and wiring of these components into a coherent, working system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
