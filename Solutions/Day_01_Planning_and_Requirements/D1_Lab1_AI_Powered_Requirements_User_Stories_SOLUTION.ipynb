{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Lab 1: AI-Powered Requirements & User Stories (Solution)\n",
    "\n",
    "**Objective:** Use a Large Language Model (LLM) to decompose a vague problem statement into structured features, user personas, and Agile user stories, culminating in a machine-readable JSON artifact.\n",
    "\n",
    "**Introduction:**\n",
    "This notebook contains the complete solution for Lab 1. It demonstrates how to use an LLM to systematically break down a problem, generate structured requirements, and programmatically validate the output. Each step includes explanations of the code and the reasoning behind the prompts.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Purpose:** This initial block of code prepares our environment for the lab. It adds the project root to the system path to ensure our `utils` package can be imported, and then initializes the LLM API client.\n",
    "\n",
    "**Model Selection:**\n",
    "Our `utils` package is configured to work with multiple AI providers. You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in the `RECOMMENDED_MODELS` dictionary in `utils`. For example, to use a Hugging Face model, you could change the line to: `client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")`\n",
    "\n",
    "**Libraries Explained:**\n",
    "- **`os`**, **`sys`**: Standard Python libraries for interacting with the file system and Python's path, ensuring our modules are discoverable.\n",
    "- **`json`**: A standard library for working with JSON data. We use `json.loads` to parse the LLM's text output into a Python dictionary or list, and `json.dumps` to format Python objects into a pretty-printed JSON string for saving.\n",
    "- **`utils`**: Our custom helper script. \n",
    "  - `setup_llm_client()`: Handles reading the `.env` file and initializing the API client.\n",
    "  - `get_completion()`: Simplifies the process of sending a prompt to the LLM and receiving a text response.\n",
    "  - `save_artifact()`: Ensures our project artifacts are stored consistently in the `artifacts` directory.\n",
    "  - `clean_llm_output()`: A new standardized function to remove markdown fences from LLM outputs.\n",
    "  - `prompt_enhancer()`: An advanced meta-prompt system that takes raw user input and optimizes it using prompt engineering best practices, including role assignment, context grounding, and structural organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output, recommended_models_table, prompt_enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Model | Provider | Text | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| MiniMaxAI/MiniMax-M2 | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 128,000 | 8,192 |\n",
       "| Qwen/Qwen3-VL-235B-A22B-Instruct | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 32,768 | 8,192 |\n",
       "| black-forest-labs/FLUX.1-Kontext-dev | huggingface | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | - | - |\n",
       "| claude-3-5-haiku-20241022 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 8,192 |\n",
       "| claude-haiku-4-5-20251001 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 32,000 |\n",
       "| claude-opus-4-1-20250805 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 32,000 |\n",
       "| claude-opus-4-5-20251101 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 64,000 |\n",
       "| claude-sonnet-4-5-20250929 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 64,000 |\n",
       "| dall-e-3 | openai | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚ùå | - | - |\n",
       "| deepseek-ai/DeepSeek-V3.1 | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 128,000 | 100,000 |\n",
       "| gemini-2.0-flash-exp | google | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,048,576 | 8,192 |\n",
       "| gemini-2.5-flash | google | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-flash-image-preview | google | ‚ùå | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | 32,768 | 32,768 |\n",
       "| gemini-2.5-flash-lite | google | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-pro | google | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,048,576 | 65,536 |\n",
       "| gpt-4.1 | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 32,768 |\n",
       "| gpt-4.1-mini | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 32,000 |\n",
       "| gpt-4.1-nano | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 32,000 |\n",
       "| gpt-4o | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 128,000 | 16,384 |\n",
       "| gpt-4o-mini | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 128,000 | 16,384 |\n",
       "| gpt-4o-mini-transcribe | openai | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | - | - |\n",
       "| gpt-4o-transcribe | openai | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | - | - |\n",
       "| meta-llama/Llama-3.3-70B-Instruct | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 8,192 | 4,096 |\n",
       "| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 100,000 |\n",
       "| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 100,000 |\n",
       "| o3 | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 100,000 |\n",
       "| o3-mini | openai | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 200,000 | 100,000 |\n",
       "| o4-mini | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 100,000 |\n",
       "| stabilityai/stable-diffusion-3.5-large | huggingface | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚ùå | - | - |\n",
       "| whisper-1 | openai | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | - | - |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'| Model | Provider | Text | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\\n|---|---|---|---|---|---|---|---|---|\\n| MiniMaxAI/MiniMax-M2 | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 128,000 | 8,192 |\\n| Qwen/Qwen3-VL-235B-A22B-Instruct | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 32,768 | 8,192 |\\n| black-forest-labs/FLUX.1-Kontext-dev | huggingface | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | - | - |\\n| claude-3-5-haiku-20241022 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 8,192 |\\n| claude-haiku-4-5-20251001 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 32,000 |\\n| claude-opus-4-1-20250805 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 32,000 |\\n| claude-opus-4-5-20251101 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 64,000 |\\n| claude-sonnet-4-5-20250929 | anthropic | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 64,000 |\\n| dall-e-3 | openai | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚ùå | - | - |\\n| deepseek-ai/DeepSeek-V3.1 | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 128,000 | 100,000 |\\n| gemini-2.0-flash-exp | google | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,048,576 | 8,192 |\\n| gemini-2.5-flash | google | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,048,576 | 65,536 |\\n| gemini-2.5-flash-image-preview | google | ‚ùå | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | 32,768 | 32,768 |\\n| gemini-2.5-flash-lite | google | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,048,576 | 65,536 |\\n| gemini-2.5-pro | google | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,048,576 | 65,536 |\\n| gpt-4.1 | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 32,768 |\\n| gpt-4.1-mini | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 32,000 |\\n| gpt-4.1-nano | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 32,000 |\\n| gpt-4o | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 128,000 | 16,384 |\\n| gpt-4o-mini | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 128,000 | 16,384 |\\n| gpt-4o-mini-transcribe | openai | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | - | - |\\n| gpt-4o-transcribe | openai | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | - | - |\\n| meta-llama/Llama-3.3-70B-Instruct | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 8,192 | 4,096 |\\n| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 100,000 |\\n| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 1,000,000 | 100,000 |\\n| o3 | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 100,000 |\\n| o3-mini | openai | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | 200,000 | 100,000 |\\n| o4-mini | openai | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | 200,000 | 100,000 |\\n| stabilityai/stable-diffusion-3.5-large | huggingface | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚ùå | - | - |\\n| whisper-1 | openai | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | - | - |'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_models_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 09:52:09,068 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n",
      "/Users/agaleana/repos/AG-AISOFTDEV/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-01 09:52:09,161 ag_aisoftdev.utils INFO LLM Client configured provider=huggingface model=deepseek-ai/DeepSeek-V3.1 latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "brainstormed_features_client, brainstormed_features_model_name, brainstormed_features_api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "user_personas_client, user_personas_model_name, user_personas_api_provider = setup_llm_client(model_name=\"deepseek-ai/DeepSeek-V3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Problem Statement\n",
    "\n",
    "We define our starting point‚Äîa simple, high-level problem statement‚Äîas a Python variable. This makes it easy to reuse in multiple prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"We need a tool to help our company's new hires get up to speed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges\n",
    "\n",
    "Here are the complete solutions for each challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Brainstorming Features\n",
    "\n",
    "**Explanation:**\n",
    "This first challenge demonstrates the power of prompt enhancement. We start with simple, raw prompts for brainstorming features and identifying user personas. However, instead of using these basic prompts directly, we pass them through our `prompt_enhancer` function, which applies advanced prompt engineering techniques to optimize them.\n",
    "\n",
    "The `prompt_enhancer` automatically:\n",
    "- Assigns appropriate expert personas (e.g., \"You are a Senior Product Manager\")\n",
    "- Provides structured context and grounding\n",
    "- Defines clear task instructions with assertive action verbs\n",
    "- Sets explicit output format expectations\n",
    "- Organizes the prompt with clear structural delimiters\n",
    "\n",
    "**Key Efficiency Features:**\n",
    "- We reuse the existing LLM clients that were already initialized, avoiding duplicate setup\n",
    "- Different models can be used for different tasks (e.g., Gemini for features, DeepSeek for personas)\n",
    "- The personas prompt includes the brainstormed features as context for better coherence\n",
    "\n",
    "This enhancement process transforms simple requests into highly optimized prompts that produce more focused, detailed, and useful outputs. The goal is to generate a broad set of high-quality ideas (features and personas) that will serve as the foundation for the more structured tasks to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHALLENGE 1: AI-POWERED REQUIREMENTS GENERATION\n",
      "============================================================\n",
      "\n",
      "--- STEP 1: ENHANCING FEATURES PROMPT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 09:52:09,428 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brainstorm Enhanced prompt\n",
      " <persona>\n",
      "You are a senior HR Technology Product Manager with deep expertise in designing high-impact onboarding software for enterprise companies.\n",
      "</persona>\n",
      "\n",
      "<context>\n",
      "Problem statement: ‚ÄúWe need a tool to help our company‚Äôs new hires get up to speed.‚Äù\n",
      "Goal: Brainstorm a comprehensive set of potential features for a new-hire onboarding tool that accelerates ramp-up, fosters engagement, and ensures compliance.\n",
      "</context>\n",
      "\n",
      "<instructions>\n",
      "1. Think step by step to generate a diverse, non-overlapping list of actionable features spanning the entire onboarding lifecycle (e.g., pre-boarding, first-day logistics, training, social integration, feedback loops, analytics, scalability).\n",
      "2. Prioritize practicality and user value; avoid vague or redundant items.\n",
      "3. Provide only the feature names‚Äîno explanations or extra commentary.\n",
      "</instructions>\n",
      "\n",
      "<output_format>\n",
      "Return the results as a simple Markdown unordered list, each feature preceded by ‚Äú- ‚Äù (dash + space). No additional text.\n",
      "</output_format>\n",
      "\n",
      "--- STEP 2: GENERATING BRAINSTORMED FEATURES ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 09:52:40,797 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Digital Offer Letter Acceptance\n",
      "- Automated Pre-Boarding Welcome Journey\n",
      "- New Hire Paperwork & E-Signature Collection\n",
      "- IT Provisioning & Equipment Tracker\n",
      "- Background Check Status Integration\n",
      "- Personalized First-Day Agenda\n",
      "- Team Introduction Portal with Bios\n",
      "- Onboarding Buddy/Mentor Matching\n",
      "- Role-Specific 30-60-90 Day Plan Templates\n",
      "- Task Management with Automated Reminders\n",
      "- Manager Dashboard for Team Onboarding Progress\n",
      "- New Hire Cohort Directory & Group Chat\n",
      "- Customizable Learning Paths\n",
      "- Micro-learning Content Library\n",
      "- LMS Integration for Formal Training\n",
      "- Scheduled 1:1 Meeting Prompts for Managers\n",
      "- Stakeholder Introduction Meeting Scheduler\n",
      "- Benefits Enrollment Guide & Deadline Tracker\n",
      "- Company Org Chart Explorer\n",
      "- \"Meet a Colleague\" Coffee Chat Matcher\n",
      "- Employee Resource Group (ERG) Discovery\n",
      "- Company Jargon & Acronym Dictionary\n",
      "- New Hire Pulse Surveys (7, 30, 90 days)\n",
      "- Anonymous Feedback & Question Box\n",
      "- Peer Recognition & Kudos System\n",
      "- Gamified Onboarding Milestones & Badges\n",
      "- HRIS Data Sync & Integration\n",
      "- ATS Candidate Data Handoff\n",
      "- Single Sign-On (SSO) Authentication\n",
      "- Native Mobile Application\n",
      "- Onboarding Journey Builder for Admins\n",
      "- Role-Based Access Controls\n",
      "- Compliance Training & Certification Tracking\n",
      "- Onboarding Analytics & Ramp-Time Metrics Dashboard\n",
      "- Customizable Branding & White-Labeling\n",
      "- Global Localization & Language Support\n",
      "- Offboarding Workflow Automation\n",
      "\n",
      "--- STEP 3: ENHANCING PERSONAS PROMPT ---\n",
      "Personas Enhanced prompt\n",
      " <prompt>\n",
      "  \n",
      "  <persona>\n",
      "    You are a Senior Employee-Experience Product Strategist who specializes in HR technology and user-persona development.\n",
      "  </persona>\n",
      "\n",
      "  <context>\n",
      "    Our company is designing an end-to-end digital onboarding platform for new hires.  \n",
      "    Key pain-point: ‚ÄúWe need a tool to help our company‚Äôs new hires get up to speed.‚Äù  \n",
      "    Brainstormed feature set (non-exhaustive):  \n",
      "      ‚Ä¢ Digital Offer Letter Acceptance ‚Ä¢ Automated Pre-Boarding Welcome Journey ‚Ä¢ New Hire Paperwork & E-Signature Collection ‚Ä¢ IT Provisioning & Equipment Tracker ‚Ä¢ Background Check Status Integration ‚Ä¢ Personalized First-Day Agenda ‚Ä¢ Team Introduction Portal with Bios ‚Ä¢ Onboarding Buddy/Mentor Matching ‚Ä¢ Role-Specific 30-60-90 Day Plan Templates ‚Ä¢ Task Management with Automated Reminders ‚Ä¢ Manager Dashboard for Team Onboarding Progress ‚Ä¢ New Hire Cohort Directory & Group Chat ‚Ä¢ Customizable Learning Paths ‚Ä¢ Micro-learning Content Library ‚Ä¢ LMS Integration ‚Ä¢ Scheduled 1:1 Meeting Prompts ‚Ä¢ Stakeholder Introduction Scheduler ‚Ä¢ Benefits Enrollment Guide & Deadline Tracker ‚Ä¢ Company Org Chart Explorer ‚Ä¢ ‚ÄúMeet a Colleague‚Äù Coffee Chat Matcher ‚Ä¢ Employee Resource Group Discovery ‚Ä¢ Company Jargon Dictionary ‚Ä¢ New Hire Pulse Surveys (7-, 30-, 90-day) ‚Ä¢ Anonymous Feedback Box ‚Ä¢ Peer Recognition System ‚Ä¢ Gamified Onboarding Badges ‚Ä¢ HRIS & ATS Integrations ‚Ä¢ SSO Authentication ‚Ä¢ Native Mobile App ‚Ä¢ Journey Builder for Admins ‚Ä¢ Role-Based Access Controls ‚Ä¢ Compliance Training & Certification Tracking ‚Ä¢ Analytics Dashboard ‚Ä¢ Custom Branding ‚Ä¢ Global Localization ‚Ä¢ Offboarding Workflow Automation.\n",
      "  </context>\n",
      "\n",
      "  <instructions>\n",
      "    1. Think methodically about the various stakeholder groups that will interact with the platform.  \n",
      "    2. Generate exactly three distinct user personas.  \n",
      "    3. For each persona, provide:  \n",
      "       a. Persona Name & Role (1 line)  \n",
      "       b. Brief Bio (2-3 sentences)  \n",
      "       c. Primary Goal or ‚ÄúJob-to-be-Done‚Äù when using the platform (1 concise sentence).  \n",
      "    4. Ensure the personas are clearly differentiated in seniority, responsibilities, and perspective (e.g., new hire vs. manager vs. HR admin).  \n",
      "    5. Base all details on the provided context; do not invent features that are not listed.\n",
      "  </instructions>\n",
      "\n",
      "  <output_format>\n",
      "    Respond in Markdown using the following template:\n",
      "\n",
      "    ### Persona 1: *Name ‚Äì Role*  \n",
      "    **Bio:** ‚Ä¶  \n",
      "    **Primary Goal:** ‚Ä¶\n",
      "\n",
      "    ### Persona 2: *Name ‚Äì Role*  \n",
      "    **Bio:** ‚Ä¶  \n",
      "    **Primary Goal:** ‚Ä¶\n",
      "\n",
      "    ### Persona 3: *Name ‚Äì Role*  \n",
      "    **Bio:** ‚Ä¶  \n",
      "    **Primary Goal:** ‚Ä¶\n",
      "  </output_format>\n",
      "\n",
      "</prompt>\n",
      "\n",
      "--- STEP 4: GENERATING USER PERSONAS ---\n",
      "### Persona 1: Chloe Davis ‚Äì New Marketing Associate\n",
      "**Bio:** Chloe is a recent university graduate starting her first full-time professional role. She is excited but anxious about making a good impression and understanding the company culture. She is digitally native and expects a seamless, intuitive, and supportive onboarding experience.\n",
      "**Primary Goal:** To efficiently complete all pre-boarding tasks, understand her role and team, and build a sense of belonging before her first day, reducing first-day anxiety.\n",
      "\n",
      "### Persona 2: David Chen ‚Äì Engineering Manager\n",
      "**Bio:** David is a seasoned manager leading a team of twelve software engineers. He is extremely busy and needs to balance his own project deliverables with the responsibility of integrating new hires into his high-performing team. He values efficiency, visibility, and ensuring his new reports are productive quickly.\n",
      "**Primary Goal:** To effortlessly track the onboarding progress of his new hires, ensure they have the necessary tools and introductions, and proactively identify any roadblocks without significant manual effort.\n",
      "\n",
      "### Persona 3: Anya Sharma ‚Äì Senior HR Business Partner\n",
      "**Bio:** Anya is responsible for the end-to-end employee experience for a business unit of 500 people. She is a strategic partner who designs onboarding processes, ensures compliance, and uses data to improve retention and engagement from day one. She needs a scalable, configurable system.\n",
      "**Primary Goal:** To design, automate, and monitor standardized yet personalized onboarding journeys for diverse roles, ensuring compliance and gathering actionable feedback to continuously improve the program.\n",
      "\n",
      "============================================================\n",
      "CHALLENGE 1 COMPLETED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Challenge 1: Brainstorming Features and User Personas\n",
    "print(\"=\" * 60)\n",
    "print(\"CHALLENGE 1: AI-POWERED REQUIREMENTS GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Enhance Features Prompt\n",
    "print(\"\\n--- STEP 1: ENHANCING FEATURES PROMPT ---\")\n",
    "raw_features_prompt = f\"Based on the problem statement: '{problem_statement}', brainstorm a list of potential features for a new hire onboarding tool. Format the output as a simple markdown list.\"\n",
    "\n",
    "enhanced_features_prompt = prompt_enhancer(raw_features_prompt)\n",
    "print(\"Brainstorm Enhanced prompt\\n\", enhanced_features_prompt)\n",
    "\n",
    "# Step 2: Generate Brainstormed Features\n",
    "print(\"\\n--- STEP 2: GENERATING BRAINSTORMED FEATURES ---\")\n",
    "brainstormed_features = get_completion(\n",
    "    enhanced_features_prompt,\n",
    "    brainstormed_features_client,\n",
    "    brainstormed_features_model_name,\n",
    "    brainstormed_features_api_provider\n",
    ")\n",
    "print(brainstormed_features)\n",
    "\n",
    "# Step 3: Enhance Personas Prompt\n",
    "print(\"\\n--- STEP 3: ENHANCING PERSONAS PROMPT ---\")\n",
    "raw_personas_prompt = f\"Based on the problem statement: '{problem_statement}' and the following brainstormed features: {brainstormed_features}, identify and describe three distinct user personas who would interact with this tool. For each persona, describe their role and main goal.\"\n",
    "\n",
    "enhanced_personas_prompt = prompt_enhancer(raw_personas_prompt)\n",
    "print(\"Personas Enhanced prompt\\n\", enhanced_personas_prompt)\n",
    "\n",
    "# Step 4: Generate User Personas\n",
    "print(\"\\n--- STEP 4: GENERATING USER PERSONAS ---\")\n",
    "user_personas = get_completion(\n",
    "    enhanced_personas_prompt,\n",
    "    user_personas_client,\n",
    "    user_personas_model_name,\n",
    "    user_personas_api_provider\n",
    ")\n",
    "print(user_personas)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CHALLENGE 1 COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
    "\n",
    "**Explanation:**\n",
    "This challenge represents a significant increase in complexity and value. We are no longer asking for simple text; we are demanding a specific, structured data format (JSON). \n",
    "\n",
    "The prompt is carefully engineered:\n",
    "1.  **Persona:** `You are a Senior Product Manager...` tells the LLM the role it should adopt.\n",
    "2.  **Context:** We provide the previous outputs (`problem_statement`, `brainstormed_features`, `user_personas`) inside `<context>` tags to give the LLM all the necessary information.\n",
    "3.  **Format:** The `OUTPUT REQUIREMENTS` section is extremely explicit. It tells the LLM to *only* output JSON, defines the exact keys for each object, and specifies the format for nested data (like the array of Gherkin strings). This strictness is key to getting reliable, machine-readable output.\n",
    "4.  **Parsing:** The `try...except` block is a crucial step. It attempts to parse the LLM's string output into a Python list of dictionaries. If it succeeds, we know the LLM followed our instructions perfectly. If it fails, we print the raw output to help debug the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 09:53:02,161 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHALLENGE 2: GENERATING FORMAL USER STORIES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 09:53:18,040 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=gpt-4o latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON User Stories Enhanced prompt\n",
      " <role>\n",
      "You are a Senior Agile Product Owner and user-story expert specializing in employee onboarding platforms.\n",
      "</role>\n",
      "\n",
      "<context>\n",
      "Problem Statement:\n",
      "We need a tool to help our company‚Äôs new hires get up to speed.\n",
      "\n",
      "Potential Features:\n",
      "‚Ä¢ Digital Offer Letter Acceptance\n",
      "‚Ä¢ Automated Pre-Boarding Welcome Journey\n",
      "‚Ä¢ New Hire Paperwork & E-Signature Collection\n",
      "‚Ä¢ IT Provisioning & Equipment Tracker\n",
      "‚Ä¢ Background Check Status Integration\n",
      "‚Ä¢ Personalized First-Day Agenda\n",
      "‚Ä¢ Team Introduction Portal with Bios\n",
      "‚Ä¢ Onboarding Buddy/Mentor Matching\n",
      "‚Ä¢ Role-Specific 30-60-90 Day Plan Templates\n",
      "‚Ä¢ Task Management with Automated Reminders\n",
      "‚Ä¢ Manager Dashboard for Team Onboarding Progress\n",
      "‚Ä¢ New Hire Cohort Directory & Group Chat\n",
      "‚Ä¢ Customizable Learning Paths\n",
      "‚Ä¢ Micro-learning Content Library\n",
      "‚Ä¢ LMS Integration for Formal Training\n",
      "‚Ä¢ Scheduled 1:1 Meeting Prompts for Managers\n",
      "‚Ä¢ Stakeholder Introduction Meeting Scheduler\n",
      "‚Ä¢ Benefits Enrollment Guide & Deadline Tracker\n",
      "‚Ä¢ Company Org Chart Explorer\n",
      "‚Ä¢ ‚ÄúMeet a Colleague‚Äù Coffee Chat Matcher\n",
      "‚Ä¢ Employee Resource Group (ERG) Discovery\n",
      "‚Ä¢ Company Jargon & Acronym Dictionary\n",
      "‚Ä¢ New Hire Pulse Surveys (7, 30, 90 days)\n",
      "‚Ä¢ Anonymous Feedback & Question Box\n",
      "‚Ä¢ Peer Recognition & Kudos System\n",
      "‚Ä¢ Gamified Onboarding Milestones & Badges\n",
      "‚Ä¢ HRIS Data Sync & Integration\n",
      "‚Ä¢ ATS Candidate Data Handoff\n",
      "‚Ä¢ Single Sign-On (SSO) Authentication\n",
      "‚Ä¢ Native Mobile Application\n",
      "‚Ä¢ Onboarding Journey Builder for Admins\n",
      "‚Ä¢ Role-Based Access Controls\n",
      "‚Ä¢ Compliance Training & Certification Tracking\n",
      "‚Ä¢ Onboarding Analytics & Ramp-Time Metrics Dashboard\n",
      "‚Ä¢ Customizable Branding & White-Labeling\n",
      "‚Ä¢ Global Localization & Language Support\n",
      "‚Ä¢ Offboarding Workflow Automation\n",
      "\n",
      "Personas:\n",
      "1. Chloe Davis ‚Äì New Marketing Associate  \n",
      "   Goal: Finish pre-boarding, understand team & culture, feel belonging before day one.\n",
      "\n",
      "2. David Chen ‚Äì Engineering Manager  \n",
      "   Goal: Efficiently track onboarding progress, remove roadblocks, minimize manual work.\n",
      "\n",
      "3. Anya Sharma ‚Äì Senior HR Business Partner  \n",
      "   Goal: Design, automate, and monitor standardized yet personalized journeys; ensure compliance; gather feedback at scale.\n",
      "</context>\n",
      "\n",
      "<instructions>\n",
      "TASK: Generate five (5) distinct, detailed user stories in JSON.\n",
      "\n",
      "PROCESS:\n",
      "1. Think step-by-step about which feature best serves which persona (internal reasoning only; do not reveal).\n",
      "2. For each story, choose one persona and one primary feature or capability.\n",
      "3. Write the ‚Äúuser_story‚Äù string in the exact format:  \n",
      "   ‚ÄúAs a [persona], I want [goal], so that [benefit].‚Äù\n",
      "4. Provide 3‚Äì6 acceptance criteria per story, each in Gherkin format beginning with Given/When/Then.\n",
      "5. Assign a unique integer id starting at 1.\n",
      "\n",
      "CONSTRAINTS:\n",
      "‚Ä¢ Output must be valid JSON ‚Äî a single array of exactly five objects.  \n",
      "‚Ä¢ Keys for every object: id, persona, user_story, acceptance_criteria.  \n",
      "‚Ä¢ acceptance_criteria is an array of strings; no nested objects.  \n",
      "‚Ä¢ Do NOT include any explanatory text, markdown, or comments outside the JSON array.\n",
      "</instructions>\n",
      "\n",
      "<example>\n",
      "Example user story object (for format reference only ‚Äî do not duplicate):\n",
      "{\n",
      "  \"id\": 0,\n",
      "  \"persona\": \"Sample Persona\",\n",
      "  \"user_story\": \"As a Sample Persona, I want a quick-start tutorial, so that I can be productive on day one.\",\n",
      "  \"acceptance_criteria\": [\n",
      "    \"Given I am a new user, When I log in for the first time, Then I see a quick-start tutorial modal.\",\n",
      "    \"Given I complete the tutorial, When I close it, Then the system records my completion status.\"\n",
      "  ]\n",
      "}\n",
      "</example>\n",
      "\n",
      "<output_format>\n",
      "[\n",
      "  {\n",
      "    \"id\": integer,\n",
      "    \"persona\": \"Chloe Davis | David Chen | Anya Sharma\",\n",
      "    \"user_story\": \"As a [persona], I want ‚Ä¶, so that ‚Ä¶.\",\n",
      "    \"acceptance_criteria\": [\n",
      "      \"Given ‚Ä¶\",\n",
      "      \"When ‚Ä¶\",\n",
      "      \"Then ‚Ä¶\"\n",
      "    ]\n",
      "  },\n",
      "  { four more objects‚Ä¶ }\n",
      "]\n",
      "</output_format>\n",
      "\n",
      "--- STEP 2: INITIALIZING LLM CLIENT FOR JSON USER STORIES ---\n",
      "Using model: gpt-4o provider: openai\n",
      "\n",
      "--- STEP 3: GENERATING USER STORIES AS JSON ---\n",
      "Raw LLM response length: 3140 characters\n",
      "First 200 characters of response:\n",
      "'```json\\n[\\n  {\\n    \"id\": 1,\\n    \"persona\": \"Chloe Davis\",\\n    \"user_story\": \"As a Chloe Davis, I want a personalized first-day agenda, so that I can feel prepared and welcomed on my first day.\",\\n    \"a'\n",
      "\n",
      "Cleaned JSON length: 3128 characters\n",
      "‚úÖ Successfully parsed LLM output as JSON.\n",
      "Number of user stories generated: 5\n",
      "\n",
      "--- Sample User Story ---\n",
      "{\n",
      "  \"id\": 1,\n",
      "  \"persona\": \"Chloe Davis\",\n",
      "  \"user_story\": \"As a Chloe Davis, I want a personalized first-day agenda, so that I can feel prepared and welcomed on my first day.\",\n",
      "  \"acceptance_criteria\": [\n",
      "    \"Given I have accepted the offer, When I log into the onboarding platform, Then I see a personalized first-day agenda.\",\n",
      "    \"Given I view my agenda, When I click on an agenda item, Then I see detailed information about that item.\",\n",
      "    \"Given I have questions about my agenda, When I contact support, Then I receive a response within 24 hours.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Challenge 2: Generating Formal User Stories\n",
    "print(\"=\" * 60)\n",
    "print(\"CHALLENGE 2: GENERATING FORMAL USER STORIES\")\n",
    "\n",
    "raw_json_prompt = f\"\"\"\n",
    "You are a Senior Product Manager creating a product backlog for a new hire onboarding tool.\n",
    "\n",
    "Based on the following context:\n",
    "<context>\n",
    "Problem Statement: {problem_statement}\n",
    "Potential Features: {brainstormed_features}\n",
    "User Personas: {user_personas}\n",
    "</context>\n",
    "\n",
    "Your task is to generate a list of 5 detailed user stories.\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- You MUST output a valid JSON array. Your response must begin with [ and end with ]. Do not include any text or markdown before or after the JSON array.\n",
    "- Each object in the array must represent a single user story.\n",
    "- Each object must have the following keys: 'id' (an integer), 'persona' (a string from the personas), 'user_story' (a string in the format 'As a [persona], I want [goal], so that [benefit].'), and 'acceptance_criteria' (an array of strings, with each string in Gherkin format 'Given/When/Then').\n",
    "\"\"\"\n",
    "\n",
    "enhanced_json_prompt = prompt_enhancer(raw_json_prompt)\n",
    "print(\"JSON User Stories Enhanced prompt\\n\", enhanced_json_prompt)\n",
    "\n",
    "# Step 2: Initialize LLM client for JSON user stories\n",
    "print(\"\\n--- STEP 2: INITIALIZING LLM CLIENT FOR JSON USER STORIES ---\")\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "print(f\"Using model: {model_name} provider: {api_provider}\")\n",
    "\n",
    "# Step 3: Generate User Stories as JSON\n",
    "print(\"\\n--- STEP 3: GENERATING USER STORIES AS JSON ---\")\n",
    "# We set a lower temperature to encourage the LLM to stick to the requested format.\n",
    "json_output_str = get_completion(enhanced_json_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "print(f\"Raw LLM response length: {len(json_output_str)} characters\")\n",
    "print(\"First 200 characters of response:\")\n",
    "print(repr(json_output_str[:200]))\n",
    "\n",
    "# Attempt to parse the string output into a Python list.\n",
    "try:\n",
    "    # Use our new standardized cleaning function from utils\n",
    "    cleaned_json_str = clean_llm_output(json_output_str, language='json')\n",
    "    print(f\"\\nCleaned JSON length: {len(cleaned_json_str)} characters\")\n",
    "    \n",
    "    user_stories_json = json.loads(cleaned_json_str)\n",
    "    print(\"‚úÖ Successfully parsed LLM output as JSON.\")\n",
    "    print(f\"Number of user stories generated: {len(user_stories_json)}\")\n",
    "    \n",
    "    # Pretty-print the first user story to verify its structure\n",
    "    print(\"\\n--- Sample User Story ---\")\n",
    "    print(json.dumps(user_stories_json[0], indent=2))\n",
    "    \n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"‚ùå Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"\\n--- DEBUGGING INFO ---\")\n",
    "    print(\"Raw LLM Output preview (truncated to 1000 chars):\")\n",
    "    if 'json_output_str' in locals() and json_output_str:\n",
    "        print(\"-\" * 60)\n",
    "        print(json_output_str[:1000])\n",
    "        print(\"-\" * 60)\n",
    "    else:\n",
    "        print(\"  <No raw LLM output (json_output_str) available>\")\n",
    "\n",
    "    print(\"\\n‚ö†Ô∏è  Setting user_stories_json to an empty list to prevent downstream errors.\")\n",
    "    user_stories_json = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
    "\n",
    "**Explanation:**\n",
    "This is the final and most critical step. We treat the LLM's output as untrusted input and subject it to programmatic validation. This ensures that the artifact we create is reliable and can be consumed by other automated tools in later stages of the SDLC without causing errors. \n",
    "\n",
    "The `validate_and_save_stories` function acts as a gatekeeper. It checks for the correct data types (a list of objects) and ensures that all required fields are present in each object. Only if all checks pass do we proceed to save the file using `save_artifact`. This creates a trustworthy `day1_user_stories.json` file that can be confidently used as an input for other automated processes in our SDLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_save_stories(stories_data):\n",
    "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
    "    if not isinstance(stories_data, list) or not stories_data:\n",
    "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
    "        return False\n",
    "\n",
    "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
    "    all_stories_valid = True\n",
    "\n",
    "    # Loop through each story object in the list.\n",
    "    for i, story in enumerate(stories_data):\n",
    "        # Check for the presence of all required keys.\n",
    "        if not all(key in story for key in required_keys):\n",
    "            print(f\"Validation Failed: Story at index {i} is missing one or more required keys.\")\n",
    "            print(f\"   Expected keys: {required_keys}\")\n",
    "            print(f\"   Found keys: {list(story.keys()) if isinstance(story, dict) else 'Not a dictionary'}\")\n",
    "            all_stories_valid = False\n",
    "            continue # Don't bother with further checks for this invalid story\n",
    "        \n",
    "        # Check that the acceptance criteria is a list with at least one item.\n",
    "        ac = story.get('acceptance_criteria')\n",
    "        if not isinstance(ac, list) or not ac:\n",
    "            print(f\"Validation Failed: Story at index {i} (ID: '{story.get('id')}') has invalid or empty acceptance criteria.\")\n",
    "            print(f\"   Expected: list with at least one item\")\n",
    "            print(f\"   Found: {type(ac)} with value {ac}\")\n",
    "            all_stories_valid = False\n",
    "\n",
    "    # Only save the artifact if all stories in the list are valid.\n",
    "    if all_stories_valid:\n",
    "        print(f\"\\n‚úÖ All {len(stories_data)} user stories passed validation.\")\n",
    "        artifact_path = \"artifacts/day1_user_stories.json\"\n",
    "        \n",
    "        # Use the helper function to save the file, creating the 'artifacts' directory if needed.\n",
    "        # We use json.dumps with an indent to make the saved file human-readable.\n",
    "        save_artifact(json.dumps(stories_data, indent=2), artifact_path)\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Validation failed for one or more stories. Artifact not saved.\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIAGNOSTIC INFO ===\n",
      "user_stories_json exists: <class 'list'>\n",
      "Length: 5\n",
      "Sample content: {'id': 1, 'persona': 'Chloe Davis', 'user_story': 'As a Chloe Davis, I want a personalized first-day agenda, so that I can feel prepared and welcomed on my first day.', 'acceptance_criteria': ['Given I have accepted the offer, When I log into the onboarding platform, Then I see a personalized first-day agenda.', 'Given I view my agenda, When I click on an agenda item, Then I see detailed information about that item.', 'Given I have questions about my agenda, When I contact support, Then I receive a response within 24 hours.']}\n",
      "\n",
      "Raw LLM output length: 3140 characters\n",
      "First 200 characters of raw output:\n",
      "'```json\\n[\\n  {\\n    \"id\": 1,\\n    \"persona\": \"Chloe Davis\",\\n    \"user_story\": \"As a Chloe Davis, I want a personalized first-day agenda, so that I can feel prepared and welcomed on my first day.\",\\n    \"a'\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Check the current state of user_stories_json\n",
    "print(\"=== DIAGNOSTIC INFO ===\")\n",
    "if 'user_stories_json' in locals():\n",
    "    print(f\"user_stories_json exists: {type(user_stories_json)}\")\n",
    "    print(f\"Length: {len(user_stories_json) if hasattr(user_stories_json, '__len__') else 'N/A'}\")\n",
    "    if user_stories_json:\n",
    "        print(\"Sample content:\", user_stories_json[0] if len(user_stories_json) > 0 else \"Empty list\")\n",
    "    else:\n",
    "        print(\"user_stories_json is empty or falsy\")\n",
    "        print(\"This means JSON parsing likely failed in the previous cell.\")\n",
    "        print(\"Check the raw LLM output above for formatting issues.\")\n",
    "else:\n",
    "    print(\"user_stories_json variable does not exist\")\n",
    "    print(\"This means the previous cell never executed successfully\")\n",
    "\n",
    "# Also check if we have the raw output\n",
    "if 'json_output_str' in locals():\n",
    "    print(f\"\\nRaw LLM output length: {len(json_output_str)} characters\")\n",
    "    print(\"First 200 characters of raw output:\")\n",
    "    print(repr(json_output_str[:200]))\n",
    "else:\n",
    "    print(\"json_output_str not available\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDATION STEP ===\n",
      "‚úÖ Found user_stories_json with 5 stories\n",
      "\n",
      "‚úÖ All 5 user stories passed validation.\n"
     ]
    },
    {
     "ename": "ArtifactError",
     "evalue": "Artifact already exists: /Users/agaleana/repos/AG-AISOFTDEV/artifacts/day1_user_stories.json. Pass overwrite=True to replace.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArtifactError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Found user_stories_json with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(user_stories_json)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m stories\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mvalidate_and_save_stories\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_stories_json\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mvalidate_and_save_stories\u001b[39m\u001b[34m(stories_data)\u001b[39m\n\u001b[32m     31\u001b[39m     artifact_path = \u001b[33m\"\u001b[39m\u001b[33martifacts/day1_user_stories.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Use the helper function to save the file, creating the 'artifacts' directory if needed.\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# We use json.dumps with an indent to make the saved file human-readable.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43msave_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstories_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/AG-AISOFTDEV/utils/artifacts.py:169\u001b[39m, in \u001b[36msave_artifact\u001b[39m\u001b[34m(content, filename, base_dir, subdir, overwrite, encoding)\u001b[39m\n\u001b[32m    167\u001b[39m path.parent.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path.exists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite:\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ArtifactError(\n\u001b[32m    170\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mArtifact already exists: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Pass overwrite=True to replace.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    171\u001b[39m     )\n\u001b[32m    173\u001b[39m tmp = path.with_suffix(path.suffix + \u001b[33m\"\u001b[39m\u001b[33m.tmp\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mArtifactError\u001b[39m: Artifact already exists: /Users/agaleana/repos/AG-AISOFTDEV/artifacts/day1_user_stories.json. Pass overwrite=True to replace."
     ]
    }
   ],
   "source": [
    "# Run the validation function on the data we parsed from the LLM.\n",
    "print(\"=== VALIDATION STEP ===\")\n",
    "\n",
    "if 'user_stories_json' not in locals():\n",
    "    print(\"‚ùå ERROR: user_stories_json variable not found.\")\n",
    "    print(\"   Make sure to run the previous cell that generates user stories.\")\n",
    "elif not user_stories_json:\n",
    "    print(\"‚ùå ERROR: user_stories_json is empty or None.\")\n",
    "    print(\"   This usually means JSON parsing failed in the previous step.\")\n",
    "    print(\"   Solutions:\")\n",
    "    print(\"   1. Check that your API keys are correctly configured\")\n",
    "    print(\"   2. Re-run the previous cell to generate user stories\")\n",
    "    print(\"   3. Examine the raw LLM output for formatting issues\")\n",
    "    \n",
    "    # Try to re-parse if we have the raw output\n",
    "    if 'json_output_str' in locals() and json_output_str.strip():\n",
    "        print(\"\\nüîÑ Attempting to re-parse the JSON...\")\n",
    "        try:\n",
    "            cleaned_json_str = clean_llm_output(json_output_str, language='json')\n",
    "            user_stories_json = json.loads(cleaned_json_str)\n",
    "            print(\"‚úÖ Re-parsing successful! Proceeding with validation...\")\n",
    "            validate_and_save_stories(user_stories_json)\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"‚ùå Re-parsing failed: {e}\")\n",
    "            print(\"Raw output that failed to parse:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(json_output_str)\n",
    "            print(\"-\" * 50)\n",
    "else:\n",
    "    print(f\"‚úÖ Found user_stories_json with {len(user_stories_json)} stories\")\n",
    "    validate_and_save_stories(user_stories_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `day1_user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD).\n",
    "\n",
    "> **Key Takeaway:** The single most important skill demonstrated in this lab is turning unstructured ideas into structured, machine-readable data (JSON). This transformation is what enables automation and integration with other tools later in the SDLC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
